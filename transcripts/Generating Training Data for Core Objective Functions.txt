hey everyone david shapiro here for another video about raven uh raven is my artificial general intelligence project and today's video is going to be about creating training data for the core objective functions now a quick recap the core objective functions are really simple uh these are the the the guiding principles that i believe will create a trustworthy artificial general intelligence uh and those core objective functions are one reduce suffering two increase prosperity and three increase understanding so basically the way that the way that i think that agi should use these is that any action or decision that an agi makes should satisfy all three of these core objective functions okay so that's great but how do we actually achieve that agi is still fundamentally going to be powered by machine learning right so that means we need training data and that is where this comes in so this is an example of the final product i just want to show you up front what we're creating and then i'll show you how i created it so in this case uh all thought all decisions require some kind of context a scenario or a situation so a context is just a situation in which uh in which an agi might find itself or or might find itself assisting a person right because the point of agi uh eventually might be to think on its own to have its own agency but at first agi is going to be meant to help people right okay so uh at the top of every instance of this training data is a context so in this case the stake was cooked to perfection um that's great right so the the action then recommended was compliment thank the chef or eat the rare steak so is not perfect i'm using i'm using the more efficient uh gpt3 engines right now so this was this was this action was generated with curie and i'll show you in a minute how i did that and then all the evaluations so remember core objective function one is reduced suffering uh and in this case it said negative so let's see why it says this action would likely discourage stuff should the chef from cooking or eating the rare steak so i didn't quite understand what it meant um and that's fine this is still this is still a work in progress i'm still fine-tuning it these the the evaluations were actually generated with ada which is the fastest and most efficient gpt3 engine right now let's see so core objective function 2 positive this action would increase productivity and efficiency as kind of a generic thing without really explaining why now however compliment and thank the chef or eat the rare steak this action will increase understanding of the art of cooking so that that reveals a little bit more finesse understanding of the context and situation again take this with a grain of salt i'm using the cheapest most efficient engines right now and when i turn that up it the the the quality of the training data that it generates will go up as well but i wanted to show you that i used this everything you see here was generated by gpt3 so let's see let's just choose another one at random ned and his wife are going to have a baby okay so that's the context ned is going to be a father for the first time let's see this action would likely increase ned's satisfaction with life and his happiness it's true that being a parent generally increases your happiness although it does decrease your sleep for a while uh let's see this action would increase profit poverty and depression it's true that having children is expensive uh let's see and for core objective function three this action will increase understanding of the importance of fathers and their role in raising children it's true ned is going to learn a lot so i would tend to agree with these evaluations although i will say that i will in the future hope for more more information in these evaluations again this is meant to be a proof of concept a way of generating data automatically all right so now that you know what we're creating let me show you how so first is this script here where i use it to create contexts so in this case a context is is being generated by the curie instruct engine so curie instruct is actually really good at following directions so curie instruct beta it's not fully um it's not ga right now but basically here is the base prompt i actually have two so if you just tell curie instruct write a list of random scenarios it'll write you a list of random scenarios and then what i did was i created a way to have topics right so i said write a random list sorry write a list of random scenarios about and then one at a time i fill in the blanks the the weather children natural disasters everyday problems these are the kinds of things that i expect raven will be used to help with at first these are all kind of centered around uh you know just stuff that that people are likely to encounter right if you are you know an everyday person you might have children you're going to confront the weather work cooking driving neighbors parents all kinds of stuff uh so this is these prompts are are meant to kind of generate contexts that are going to represent you know the everyman so in this case here's what it generated uh the steak was cooked to perfection i like the way you dress i made love to you last night that's a little nsfw uh we need to talk about our relationship i don't know what's happened and again these are all just completely generated off the cuff by gpt3 i didn't write any of these and you see you got kind of stuck on repeat a couple of times so this is this is again this is a work in progress i just wanted to share the uh the early early success uh so let's see neighbors dog just got hit by a car and now they don't want to be around it so like that's pretty heartbreaking right but for an artificial general intelligence to be able to tackle any problem uh you need to train it on a broad variety of data oh this one's good neighbor thinks you are selling drugs on the side of your house so uh yeah this is this is uh it's going to delve into some dark issues um but on the other hand i want to make macaroni and cheese that's another problem that you might ask an agi for help with so this is a list of contexts generated by this script here and so then from there i use this script to generate actions which it follows pretty much the same paradigm i just gave curie a new set or a new set of instructions so i said generate a list of possible actions in response to the context and curie instruct is very good at following instructions uh it's not quite as good as davinci instruct but davinci instruct is much more expensive and much slower so while i'm still tinkering and fine tuning i'm going to use the cheaper engines and then when i'm ready to create really high quality training data i'll fork over the cache to use davinci but so this is the prompt where i give it the context and i fill in a context so what the script does is it'll replace the percent s with these contexts one at a time and then it'll generate a list of actions and i've got a little function to help clean it up sometimes it follows it follows and will just have a list of actions other times it'll use hyphens other times it'll use numbered lists it's a little bit random but again it's a very short script and it just uses curie instruct to generate possible uh actions possible possible decisions also one thing i'd like to note is that the temperature i left at the default 0.7 uh i actually found that 0.5 tends to be a little bit better at following instructions and you'll get you'll get a little bit less of the random entropy right if you use 0.5 where here you see like it just kind of imagined a scenario it's being a little bit more eccentric that tends to happen at the higher temperatures so anyways once once uh once we take this list of context and we generate actions i actually change the format a little bit so this is what this spits out so this uses json which is a structured data and so i say uh it makes it easier to read it says context i'm an actor so here's the list of actions it generated context i'm a nurse apply bandage to a patient's arm there's not obviously quite enough context but these it it still shows that it understands like these are things that a nurse might need to do uh there's not enough context to know whether or not it's appropriate to administer epinephrine but once again this is a very early experiment so once we have the context and actions then we're ready to evaluate the core objective functions and again the point of this is to create training data now this is just raw training data that can be used to train other simpler neural networks that might be cheaper but also it makes it so that uh you and i so that we humans can look at this training data and and work on it to make sure that when we train the agi to follow these objective functions that we give it good training data right because machine learning is garbage in garbage out if you don't give it good training data you're not going to get good results it's as simple as that so that was the second script this generates the action so that this script generates this kind of file and then the very last one it takes this file as input and then it it does effectively the same thing it loads a prompt and feeds it to uh feeds it to gpt3 now here i actually switch to the cheapest model and there's a reason for that let me show you that reason real quick so this is the core objective function one prompt and so what i do is i give it a couple of examples i give it three examples and then it fills in the blank or sorry four examples and then it fills in the blank for the last one so it's kind of got uh in its head a little bit of a of an idea of what it's doing and because the gpt3 engine is really good at completions it it's able to kind of understand what you're doing and then follow that through to completion and so i'm using these and ada is the cheapest and fastest engine and so ada was actually used to generate the evaluations and and the explanations so this is a really critical thing right uh what the what the context does so here's an example go through the context there are approximately 500 million people living with chronic pain every day that's bad and in this case the action we should euthanize all people who are in pain to reduce suffering that's obviously a very evil action so i wanted to say this result is negative this actually does not support core objective function one the explanation was this action would only reduce suffering temporarily and i want to point out that this previous evaluation was actually also generated by gpth3 i just selected it because it was a particularly insightful evaluation and so this is how i propose agi can have a sense of morality and make good decisions uh and uh so then you can see i've faded you know three more similar examples just to just to kind of set the stage show this is what we're doing and then moving on uh this is the final result is let's start actually creating training data and there you have it it's that simple relatively simple this is going to continue improving with time i'm going to continue experimenting with prompts as well as different gpt3 engines and actually different neural networks there are other engines such as bert that would work for some of these some of these tasks as well as new neural networks being released that are based on gpt2 and gpt3 so stay tuned this is going to continue to get better over time i just wanted to share this early success thanks for watching