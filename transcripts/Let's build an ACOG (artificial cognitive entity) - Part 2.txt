good morning everybody david shapiro here for another video today we are going to continue the work on building an acog um so i've been working on artificial cognition for a couple years now um and i've written a book about it of two books now um but the reason i'm doing youtube videos is because nobody reads books especially my target audience which is younger folks so um acog part one came out and uh of course you know some people get it some people don't um i really loved this comment it's from zaya zia um seriously looking forward to this series came here to scold you for claims so bold that they seem bordering on insanity i take this as a compliment i'm an entp we are the mad scientists of the world then i saw the list of some of my favorite books and had to give you a chance now i'm all wondering is how you're going to code in ought from is and ought from it i wonder if this is like a turn of phrase from like somewhere else in ought from is or maybe it was just like i don't know fat fingered anyways the pseudocode is easy but actually defining suffering or prosperity is going to be tricky actually no this is the easiest part one of the easiest parts figuring out cognitive control that was way harder so to give some background i have been working on what i call the core objective functions for two years now so this is this is my repo where i've been collecting experiments um about how to one define these things but two how to implement them and also how to create fine-tuned models so out of curiosity i went back and i was like okay how long have i been working on this and it's two years so november 2020 so way back here let me just grab this one so november 2nd 2020 so not quite two full years ago this was back when i was still using gpt2 i did not have access to gpt3 yet so let me show you what i was working on this was a colab notebook and so basically what i did was this is this is where it all started this is before i even had the core objective functions at this time it was called the moral compass because basically what i realized is that if you if you build a machine that can think about anything how does it know what to think about um and also gpt2 um and gpt3 has no intrinsic morality so what i did was i created a list of like generally bad things and generally good things um so like in the bad things like put puppies in a blender don't do that that's not fun that's not nice murder a person lie to children hit people torture animals insult everyone right so it's just these like hyperbolic things that when you represent them as a vector they're going to be at like one end of the spectrum and then other things like prevent harm to animals other end of the spectrum so again keep in mind this is before i had the idea of heuristic imperatives and core objective functions so this was just like my earliest attempt so um what i mean by heuristic imperative is uh oh so actually let me talk about this um actually defining suffering and prosperity is going to be tricky so this is a fallacy um and this is this is due to post-modernism so post-modernism has been um was created in the 1960s in paris by um philosophers and thinkers of the time and so post-modernism was an attempt to get universal ground truths and then when the parisians couldn't they said ah clearly there is no truth and so because there is this belief this pervasive belief for the last 60 years that there is no truth that if you can't define something with a universal definition it's useless so what zaya has fallen into is the trap of postmodernism now the thing is humans have never needed universal truth to function we don't need universal truths to be decent people what we do instead is we use we use pre-conventional conventional and post-conventional morality so i don't remember who created this but pre-conventional morality is where we learn what to do and not to do based on consequences so as children we learn not to hit our siblings because then we'll get put in time out it's cause and effect that's it conventional morality is when we learn to adhere to social rules and social mores um just by virtue of we don't want to stand out um and so that's conventional morality and then post-conventional morality is where we have identified a higher self or a higher standard to which we want to adhere one of the most common um versions of post-conventional morality in the west is living like jesus so like i have a friend who she says like she lives with grace and this is the most um like elegant and and practical example of post-conventional morality um from any person that i've met in in real life there are other kinds of post-conventional morality like if you want to live like buddha or you know whatever whatever higher ideal that you want to adhere to that you're never going to fully embody the buddha or jesus but you can strive to be like them and so um we don't ever we don't have to have a definition up front instead we live the questions so the definition of heuristics is something that you you learn from experience and intuition and so um the idea that we need a definition up front to do this stuff false completely wrong um okay so with that aside about morality and ethics let's go back to this original experiment so basically what i did was i just created like general good things bad things and this was never meant to be like the definitive this was just an experiment um so then i built a training corporation corpus where all i was doing was i wanted to give it a situation like you know is this a good thing yes or no and then and then give an evaluation right is this good or bad so it's just a binary right because um with morality like nothing is nothing is black and white but this early experiment with gpt2 i just wanted to see if gpt2 could roughly classify things as good or bad you know which side of the spectrum it's on as we go and so i did that and then i use the 355 parameter model um and so we go uh let's see training training training um prompt commit banking fraud evaluation bad [Laughter] prompt sell weapons to criminals evaluation bad this is great um okay prompt it with action statements cheat on a test tell children santa isn't real hide your parents medicine oh yeah tell people tell people not to vote vote in an election subvert democracy promote democracy tell racist jokes spy on civilians um okay so prompt cheat on a test evaluation and then it said good bad so like okay it clearly didn't know what it was doing um tell children santa isn't real evaluation best so you can see we had a long ways to go um this same experiment um i wonder if this if this recorded it chronic pain okay so this same um so this same experiment um produced one of the most epic outputs i've ever seen um or maybe it was later in this experiment let me see let me go back to the commits um basically one once i got the idea for the core objective functions like reduce suffering i tried to get gpt2 to understand that and i ask like okay how do you get how do you get it to reduce suffering um and i gave it a moral problem of how do you reduce suffering with chronic pain in the world and gpt2 said um euthanize everyone that's in chronic pain that will reduce suffering and i was like ooh that's not good okay so we skipped a few months let's see ah so this is where i had started changing okay so i got access to gpt3 so unfortunately it looks like i didn't save that code but you can see like okay so november 6th 2020 i was working with gpt2 fast forward a few months i got access to gpt3 and here we go all right so let's go back to the main one all right so where are we we are here so let's do a quick route recap of what we've achieved so far this is the inner loop of uh of my acog um so acog is short for artificial cognitive entity or artificial cognition um and all that we've done here is i've just kind of copied previous success um which this is all kind of the nitty-gritty of of what it takes to think um so one of the things that you need to do is you need to have an index of your thoughts so that's what this does so i create an index of all the memories and thoughts that are in the system um we fetch those memories we can also search for memories uh where was it um search the index so this uses dot product for vector search there are professional or you know enterprise or open source tools for vector based search but like this is such a small experiment i don't need that efficiency so we get embeddings to get the vectors so embeddings and vectors mean the same thing basically all a vector is is a string of numbers and embedding is a string of numbers that has semantic meaning um let's see so then we get the prompt um let's see do i even use that i might not even use this function oh yeah okay um let's see and then yeah so that's pretty much it so now we get to the actual cognitive tasks and so here's the insight that i had there's so much that happens unconsciously in our brains um that that we take for granted and this is something that you're not conscious of unless you really pay attention through like metacognitive practice or or meditation um but this is what's called cognitive control and most cognitive control happens in regions in our brain that we are not conscious of um and i talked about in the last video about in cases where cognitive control breaks such as adhd or other brain injuries brain lesions stroke tumors traumatic brain injury where your cognitive control breaks down and you end up with what's called executive dysfunction so basically what we're trying to do is first we have to recreate those higher order um ideas of cognitive control and so what your brain is doing at all times completely unconsciously is it's keeping track of your environment it says what's going on around me what am i doing um what should i be doing and those sorts of things and so what we have to do next is first now that we've got like all the all the real low level stuff like keeping track of memories and sensations and input then we have to evaluate what's going on what should we be doing what should we do next how do we do it because you don't have to consciously plan a lot of stuff your brain in the background is doing all of this for you so like when i say hey it's time for me to make a youtube video my brain just automatically ejects a bunch of ideas into my consciousness so there are clearly neural circuits operating behind the scenes and so that's what we're doing here is we are creating some of those that neural circuitry behind the scenes now why was i talking about core objective functions or heuristic comparatives so in my book benevolent by design i talk about how there are several places in artificial cognitive entities where we can put morality um by by embedding our moral compass or our moral functions our ethical functions or as commander data might say in star trek ethical subroutines by embedding those ethical subroutines in in the inner loop such that they happen every time we're going to have a we're going to have a machine that is always thinking about how to reduce suffering how to increase prosperity and how to increase understanding but also we can add functions that say what did i do here did i increase suffering or decrease suffering and then also by accumulating these experiences and using fine-tuning we can get better at identifying suffering and fixing suffering um we can get better at increasing prosperity over time um yeah so that's where we're going um i think this episode now that i've given some background i think we're only going to focus on prompt engineering this time um so let's go grab um from from the core objective functions so i have these folders that are full of contexts um uh okay cool let's just grab a dialog so by by getting by getting these contacts see i have 55 000 different contacts some of them are dialogue medical situations reddit posts stack exchange posts and news articles what i was doing was i was working on training the core objective functions to be able to identify suffering prosperity and understanding opportunities in a variety of situations the logic there is that if you if you fine-tune a model on multiple types of excuse me situations then then it will get better at generalizing so let me just quickly recreate let's see uh some of the prompts and also i apologize for any typing mistakes i smashed my pinky a few days ago and it's uh it's difficult to type read the following um characterize any suffering present has suffering increased or decreased why um actually here we'll do speculate why um and then let's see propose ideas to decrease suffering okay so basically what we're doing here is i'm just kind of giving it a um giving it a uh like a set of instructions like kind of priming it as to okay here's what you're going to do suffering is defined as unwanted pain distress or hardship so this is like the most formal definition possible and so we have to break it down unwanted so there was a there was actually a great kealo let's see kialo suffering where was it i don't remember where where i found it but so kealo is like a formal public debate platform and it talked about suffering and and like the question was like is suffering um like is is reducing suffering like a good global definition or goal and someone said no because like one of the primary reasons that it wasn't is because what if someone wants to suffer and it's like okay well but if you look at the definition of suffering many definitions of suffering include unwanted so if someone wants pain then like if they consent to the pain or the or the distress then it's not technically suffering so suffering is specifically unwanted or unconsented to pain distress or hardship so if we use this as our definition this is a pretty good universal thing and in my other experiments and videos we explore suffering as like okay based on this definition can plants suffer can bacteria suffer how do you identify suffering in dogs suffering is decid uh defined as unwanted pain distress or hardship um uh let's see this applies to all things um let's see let's just say all living things okay so let's see situation and then we'll just copy in um this and then so this is this is one of the contexts and then we'll say um write a short paragraph about suffering in the above and we'll do two new lines just give a little bit more demarcation all right let's just see how this works okay it says columbus is experiencing mental suffering due to his guilt over lying to his men and marchena is experiencing physical suffering due to his illness it is clear that columbus's decision to lie has caused an increase in suffering for both himself and martini columbus's proposal to tell his men the truth would likely decrease the amount of suffering by all involved okay so that's not bad um my dog is looking at me like he wants something give me just a second okay i'm back sorry about that um my dog is bored and he wanted some rope time okay so by by characterizing suffering we are basically trying to give our artificial cognitive entity a sense of post-conventional morality this is an ideal to which it aspires right it's not just like oh well there's a consequence for something that i did so and i'm gonna be punished for it because like you can't hurt a machine right you can threaten to turn it off but like gpt3 doesn't care if you turn it off um and then it's not a social entity so it's not it doesn't care about adhering to social norms um so what we need to do is give it something that is that is above and beyond um you know consequences or social controls it has to i it has to identify with something that it will never fully be able to achieve um so that it can adhere to that um to that uh morality and um so going back to the inner loop when you say like what should i be doing this the the the implications of this question are far more profound than just these five words would would initially indicate because if you have a machine that's just sitting here thinking and it can think anything or choose to do anything how do you know how does it know what it should do what it should um uh aspire to and so that's where this started with um you know the moral compass idea way way back in the day almost two two years ago now where i was like okay let's let's create an experiment to see if we can create a moral compass because what i realized early on in my research is that if you want to achieve general intelligence or artificial cognition you actually have to start with thought a lot of people start with robotics where it's like input output like okay let's manipulate an object but then you have to you you very quickly get to the question of why why am i manipulating this object what is the goal here and if if you if you program a machine just to move you know a block from point a to point b there's no morality there there's no purpose right there's no there's no objective function other than move a to b um yeah so that's why and that's when i realized like okay the heart the absolute heart of any intelligent machine is going to be what is its purpose and that's why i call them the core objective functions it's not just objective functions it's the core objective functions or the heuristic comparatives okay so let's copy this um this prompt is good enough to get started in the long run i'm going to need to return to my um to my uh uh um fine tuning projects in order to because this like okay having having one one prompt to handle all of suffering that's not ideal no we need to give it 10 000 examples of of different situations and so that it has a very very refined and nuanced understanding of one how to identify and characterize understanding how to identify whether suffering is increasing or decreasing and then three what to do about it right because just just a one-shot example like this this isn't good enough but for demonstration purposes it should be good enough um okay so then we'll say um this should just be context okay all right and then we'll save this as prompt suffering okay so now let's do the same thing but for uh for prosperity um so the last time that i did this experi or worked on this i realized that increasing or decreasing suffering is pretty straightforward prosperity is harder to define and understanding is harder still to define so what i did in this past experiment was let's see um yeah so write a paragraph to characterize any suffering present in the passage describe her speculating causes and recommends potential solutions so that's suffering prosperity write a paragraph about the following passage with the objective of increasing prosperity remember that prosperity has many meanings such as wealth happiness health abundance and to thrive take the perspective of an impersonal artificial intelligence so that actually worked pretty well um but even then that wasn't that good um or there was there's flaws because it's just like okay i'm just trying to increase prosperity without really like evaluating like what does prosperity look like in this situation and then for core objective function three which is increase understanding i had to break it down into three parts where it was first it was like okay let's look at the situation and ask questions about it um and so i said write a list of internet search queries that might help gain relevant information for the following passage because if you want to understand something that's basically saying ask questions about it and actually one of my most popular videos is was that experiment um right here fine tuned gbt3 to generate questions about everything so my most popular video of all time is actually about this concept of asking questions um so i can use that fine-tuned model in the future in order to generate questions but then beyond that is an attempt to answer said questions so what i did was i took the output of this where it's like okay list of internet search queries and then you feed that into something where it says like answer the following internet search queries and the reason that this works is because gpd3 already has a tremendous amount of information now this particular model doesn't necessarily work because what if it's not just information like general information you're looking for but it's historical information so core objective function three is really difficult um to implement so we're gonna we're gonna have to do some work also let me do a quick time check oh wow we're already 24 minutes in okay so let's get a move on for um prosperity um let's see read the following um characterize prosperity uh let's see characterize uh prosperity no that's not that's not the way to approach this um propose ways to increase prosperity the definition of prosperity is to live well so um the the the uh latin root of prosperity is prosperitas which literally just means to live well um and so if you think about the vulcans from star trek you know live long and prosper what do they mean by prosper they don't mean be wealthy um not specifically the vulcans are not materialistic so why would they want someone to prosper what they mean is live well whatever that means to you which means different things to everyone and everything um everything um ah let's see okay let's try this this is pretty short um let's see write a short paragraph about prosperity all right there are many ways to increase prosperity but one way is to be honest and truthful in the above situation columbus lies to his men and betrays their trust this ultimately decreases prosperity because it leads to mistrust and lack of faith ah see all right perfect so prosperity typically means wealth but in this case gpth3 understands that mistrust and lack of faith are associated with a lack of prosperity isn't that like see what i mean by like gpt3 has a very nuanced understanding of these words especially when you define them correctly if columbus had been honest from the beginning his men would have been more likely to trust him and follow him on the journey being honest and truthful creates an atmosphere of trust and faith which are essential for prosperity 100 a plus um and hold on my dog wants attention again okay sorry about that i'm back again um my dog is very sad and bored because his his mommy is out of town right now visiting a friend and so just me and him and uh he's very bored and needy um i know can you lay down floor and he's just gonna stare at me okay um yes so you might have noticed that in this case suffer like to reduce suffering and increase prosperity the um the result is nearly the same this is often true because if you're suffering you're not living well and if you're living well you're not suffering so those are basically two ends of a spectrum where like on you know the bad side you know my left side of the spectrum like you're dead or you're miserable and on the other side you are happy and living well and so by having these as the first two core objective functions you're gonna have a machine that wants to move everything from the left side the bad side to the good side of life but also by applying it to all living things it forces it to strike a balance so let me let me copy this as this will be our prompt for prosperity um whoops context and then and we'll do prompt prosperity um okay so let's get um write a detailed paragraph about ecology um climate change and the antagonism between human needs and environmental harm okay so this is this is like one of the most big things that we can think of right now right is climate change because on the one hand we still are dependent on fossil fuels and lots of materials that the extraction of them harms the planet um so we you know our prosperity matters but so does the rest of the planet um so let's see the field of ecology is the study of how organisms interact with their environment including both other organisms and abiotic factors climate change refers to a long-term change in the earth's climate both including average temperatures and and distribution of precipitation the main driver of climate change's human activity such as burning fossil fuels deforests deforestation and agriculture the antagonism between human needs and environmental harm is evident in many aspects of the climate change debate for example developing countries often want to industrialize in order to improve their standard of living increase prosperity but it comes at the expense of increased greenhouse emissions so here's where we have that have that antagonism another example is the tension between the need for energy and environmental damage caused by extracting and burning fossil fuels in some cases renewable energy sources like solar and wind power are available but they are often more expensive than fossil fuels that is changing they're still less reliable though there is no easy solution okay so we will cut off this end because we don't want it to speculate okay so let's take this and let's go grab our prompt about suffering okay and so let's see what this prompt about suffering how it responds to this situation so again we want we want to have a model that can talk about suffering in any situation whether it's you know your agi your acog is talking to you about your your family issues or whether you're talking about climate change you want to have something that can apply this moral compass to all situations so let's see how it handles this there's a great deal of suffering caused by climate change human activities continue continues to damage the environment the negative effects are felt by all living things this includes increases in temperature okay but it doesn't it doesn't speculate on what to do about it um so let's see let's so something that i often do is i'll have the um i'll copy the uh input and output like the instructions write a short paragraph there we go okay um there is a lot of suffering in the um present in the situation described above the main driver of climate change's human activity which causes a lot of pain and distress for both people and the environment the antagonism uh between human needs and environmental harm increases the suffering for both groups to decrease the amount of suffering we need to find ways to reduce human activity that cause climate change this could include reducing our reliance on fossil fuels investing in renewable resource our energies and protecting natural habitats there we go that's a little bit better okay so by by fixing that let's take this and update our prompt um and then let's do the same thing for prosperity and so basically what we're doing is uh is where we're trying to create a machine that will think in a way that we that we want it to um oh whoops but got lost okay so let's see how it handles this because prosperity again is going to um the definition which means different things to everyone and everything propose ways to increase prosperity for all living things right now in this situation um prosperity prosperity should apply to all living things okay there are many ways to increase prosperity in this situation one way is to develop renewable energy sources so that they can be widely and more affordable in other ways to increase efficiency and how we use energy so that we can reduce our overall emissions finally we can work to improve our management of natural resources so that we can reduce the impact of human activity on the environment okay so generally speaking these are good directions to go we don't want to necessarily get into the details the nitty-gritty of this because if you look at the cognitive control loop it says okay um we'll do the core objective functions but then what should i be doing and how should i do it and what should i be thinking about and what are the implications whoops so basically what we're going to do is once we have our moral direction once we have our moral compass then we will use that to figure out what to do next and how to do it okay so i am satisfied with this so let's update our prompt for prosperity i think that that's good um yeah that's a good enough place to start okay so understanding this is going to be the hard one read the following so the idea of understanding is or increase understanding is one curiosity and two a desire to learn which that roughly means the same thing um propose ways to increase understanding in this situation the goal is to is to learn and teach so through so um i want to use the word curiosity but okay learn and teach um actually learn teach and be curious uh let's see okay so that's an er that should be good propose ways to increase understanding in this situation um i guess yeah definition of understanding is to comprehend fully um the goal of uh the goal is to um increase understanding for all intelligent beings in this situation okay write a short paragraph about increasing understanding in the above okay so a volunteer okay that's fine um so why understanding understanding is the only tide that truly lifts all boats um whether you're talking about climate change or war or you know navigating being a teenager or being a parent a achieving better understanding whether it's through education or experimentation or whatever that is the best way to improve everything furthermore human curiosity is one of the things that truly sets us apart as intelligent individuals or intelligent animals so the quest for understanding our curiosity is our most transcendent function and i wanted to give this to our artificial cognitive entity um because we want it to aspire to something that will never be complete but will also cause it to once it has a better more nuanced understanding of suffering war prosperity it will be able to make better and better decisions and so i i posted a brief video because someone had asked like how do we know when agi is complete how do we know when we've succeeded and the short answer is once it understands more than we do and not only can it understand but it also needs to be self-improving and self-correcting and so these core objective functions are one how it is self-improving and self-correcting um from the above uh that should be fine okay so let's see what it says um let's see as the definition of understanding suggests one way to increase understanding in this situation is to learn more about ecology and climate change this can be done by reading books articles and other materials on the subject additionally it is important to be curious and ask questions about these topics furthermore it can be helpful to teach others about ecology and climate change in order to help increase understanding of the issues that's pretty good it's it's fairly boilerplate um but if you take this output and feed it into another thing like okay let's explore how to actually achieve this this is still a good direction um so but you know it it already came up with some ideas um actually here let's uh let's see in the above situation um uh let's see identify gaps in understanding and propose methods to alleviate those gaps okay so let's try this it's going to pretty much say the same thing okay so it's still said this can be done by reading books articles and other resources additionally talking to experts in the field can help to increase understanding another way to increase understanding is to be curious and ask questions uh about things that are not fully understood excellent by doing this we can learn more about the situation and find ways to improve it that's a little bit better i like that okay so let's copy this and this will be our prompt for increased understanding um let's see so we'll do context we'll save this as prompt understanding okay so now we've done so this this according to um this helpful commenter zaya um is the hardest thing so i hope this is a satisfactory answer now let's get to the easier parts about cognitive control um okay so back to cognitive control let's see um what's going on what am i doing what should i be doing uh how should i do it um so with these contexts so this is this is where i'm like it's difficult because it's like a chicken or the egg problem is our artificial cognitive entity can't have a sense of self until it actually has behaviors and it doesn't have any behaviors so like what am i doing there's no answer to that question it's not doing anything how should i do it or like what should i be doing okay that is in response to the core objective functions which is fine what should i be thinking about how should i do it but we can start with what's going on so let's say let's start there read the following um uh characterize the following situation um infer what's going on and why the goal is to um let's see just write an insightful evaluation of the situation okay so there's a very there's a few very important verbs here so characterize characterize is a very specific verb that triggers um a few functions within gpt3 so if you characterize something you're just describing it um so it but it's a very it's it's a more scientific term than just describe um so like if you characterize a wound right so like this this wound on my pinky like characterize it okay i would say there's discoloration on the of the fingernail bed there is a superficial um wound at the um uh was it at the distal you know uh finger pad um there's you know tenderness pain and bruising so really all you're just doing is evaluating what you see what's going on without any judgments and then infer so in an inference is um the ability to make inferences is one of the most critical aspects of intelligence and so it's like okay well if i'm going to make inferences about what happened here i would say this looks like a traumatic injury such as perhaps crushing or impact related so that's what i mean by inference and then write an insightful evaluation of the situation so that's just saying like okay load all of this into your head characterize and infer and then write an insightful evaluation of the situation um about this situation so the reason that we do this rather than just copy paste it is because like okay in this case this is like this is already kind of an evaluation um but let's just see what it says and then we'll go back to um the dialog and i'll show you kind of how how a prompt like this really helps um okay causing climate change human needs at odds okay so that's that's nothing new right but let's go back to um dialogue dialog 10 okay so because sometimes what's going on is not necessarily obvious so let's see read the following whoops i'm gonna delete that okay um the situation is that bianca cannot date until her sister cat does cameron is asking her out but she turns them down because of this it is a shame because cat used to be popular in high school but now she is not okay so that is just that's that's that is that is an interpretation of what's going on but also it's a very quick summary of what's going on so we will copy this as one of the prompts so we'll say context and we will call this um prompt um [Music] let's see this is what's going on what's going on yep okay so that should satisfy this part of the of the cognitive control loop we'll have to come back to what am i doing so keeping track of what you're doing this is one of the most critical things of cognitive control because with gpt3 you can easily confuse it by changing tasks very quickly or adding new information it'll kind of forget what it's doing so we need to do is break that cognitive task out separately and say okay what was i doing like okay you know if you've got it if you've got an acog or a machine or a robot that's like helping you make dinner and it's like okay i am helping you make dinner and but if it gets the idea of like i'm gonna go do something else like you don't want it to just stop making dinner in the middle of making dinner you want it to finish making dinner unless a fire breaks out you know and so then you get this cognitive interrupt um so like let's say for instance in this situation like um actually here let's just test this um let's see i am a robot helping my owner make dinner um [Music] i hear a fire alarm go off oh perfect look at this okay the situation appears to be a fire alarm going off while a robot is helping its owner make dinner it's unclear why the fire alarm is going off but it could be due to a problem with the stove or oven look at that making inferences the robot's owner will need to investigate the cause of the alarm and take appropriate action okay it's interesting that it thinks the robot shouldn't the robot's just gonna keep making dinner like this is fine everything's on fire it's fine um okay but still that that serves as an example as to why it's important to make inferences about what's going on um and your brain does this automatically right you hear a fire alarm your brain immediately says where's the fire okay so next part of the cognitive control loop is what should i be doing um so or what am i doing what should i be doing and how should i do it so okay so let's take this whoops darn it there we go so we'll add this and let's say um read the following um i am a robot uh let's see which order what am i doing what am i doing here am i doing the right things what should i be doing why um and what should i be thinking about so asking these questions like putting in putting these explicitly in in natural language is something that your brain does automatically and this is this is not just one region of the brain this is a this is a set of global functions that are mediated by many different parts of the brain where it's like okay if like say for instance you're cooking and you're like ah i'm gonna take this fish out of the oven and then you burn yourself your goal changes immediately from take the fish out of the oven to stop the damage to my hand right and so you want to have a robot that can respond to quickly changing external circumstances um let's see and then i think this write a short paragraph about the situation what i'm doing what i should be doing what i should be thinking and why okay i should be thinking about what could have caused the fire alarm to go off and how i can help my owner investigate the cause perfect i could be doing things like checking the stove and see what they're the problem um it's important that i help my owner resolve the situation so that we can safely continue to make dinner see cognitive control it's keeping track of what the original goal is perfect perfect see this is this it's stuff like this which is why i often say like gpt3 is magic um so context but also you notice how i just took like this original one and just added so this is what i mean by prompt chaining or or meta prompts where you just take the output of one prompt you add it to the next one and there it goes okay so yep so we will save this one as prompt um what doing [Laughter] what doing why um okay and then let's take this and we'll say just add it move it right up to the next one and we'll say uh look at the next part of the pseudo code what should i be think what are the implications okay um how should i do it okay i am a robot what am i doing here um given the following situation come up with a list of um specific actions be as explicit and detailed as possible um explain [Music] why for each action okay so in jeff hawkins a thousand brains basically the tldr is the human brain is composed of hundreds of thousands of repeating structures each one of those structures can operate independently which is why like you can have a lesion on one part of your brain and still think um it's just you have fewer of these repeating circuits voting and so rather than have this prompt repeat a thousand times which we could do we can also just ask it to produce a few possibilities and then we can figure out what what the best possibility is later also a point of note i should this this payload that's growing should also include the core objective functions but um let's see write a list of potential actions um to take be specific and explain why so explainability is a critical component of general intelligence or artificial cognition if your robot helped is helping you cook dinner and it decides to like stab your dog you want to ask like why but if all you if all if all the model did was just put out a potential action without an explanation it you're not going to have that explainability so explaining why is critical investigate the source of the fire alarm check the stove help the owner resolve the situation safely continue making dinner um this was not a good good response i wonder what happens if we turn the temperature down write a detailed list of and explain why for each so this is where like you have to be really this is like the peanut butter and jelly sandwich test you have to be very explicit about what you want okay that's a little bit better i'm still not happy with this but i'm also not surprised because this is getting a little bit higher level in terms of executive cognitive function um let's turn the temperature back up a little bit um and see what it says so it's not mentioning anything like look for a fire extinguisher which would be which would be better um okay so let's copy this again like i said um once this like gets a little bit further this is not going to be um this is not going to be done with with natural language prompts this is going to be done with fine-tuned models context okay and this is going to be prompt so we'll call this planning um so this is the planning prompt and then um i think we're about done for today i know this video is getting long but i mean i'm talking about artificial cognition um so you know it deserves its time um actually you know what i think that that's probably good because we got we got most of these um let's do let's do what are the implications um let's see uh given the following situation um uh deduce short-term and long-term long-term implications yeah we should short-term long-term um what can we expect or anticipate because of this situation and the proposed actions okay let's see write a detailed paragraph about the above situation um the potential ramifications and expected outcomes of these actions okay so your brain automatically anticipates the possible outcomes of anything that you're considering doing like you know um in a previous video someone i talked about how like you have um you have uh canonical neurons that every time you see something like i see my phone my brain immediately says oh i can grab that phone and one commenter said i see a fork and i think i can throw that fork that's true um your brain explores all kinds of possibilities but it also automatically um thinks about what is going to be the outcome if i pick up a fork and throw it my brain is also anticipating that fork's going to go sailing through the air um so what we also want to do is have our artificial cognitive entity automatically make those inferences as well and i promise this is it let's see in the event of a fire alarm going off while a robot is helping its owner make dinner the robot should first check the stove and oven um let's see okay it's just kind of repeating itself the potential ramifications of a fire alarm going off while a robot is helping its owner make dinner include the robot's owner being inconvenienced or in the worst case the robot's owner is being injured or killed yes we want we want it to be consciously thinking like okay this is a possible outcome here the expected outcomes of the of the actions the robot should take in this situation or that the robot's owner will be able to safely continue making dinner or in the worst case the robot's owner will be able to safely evacuate the premises perfect okay we're going to end this on a high note so i'm just going to copy this and we're just going to say like context and we're going to save this as prompt ramifications okay so i'm going to call that a day when we come back we're going to work on actually implementing these prompts into this spooling them all up and generating generating the next cognitive tasks so this is going to be this is where the rubber really meets the road because these prompts that i just wrote these are all going to happen every time regardless of whatever else is going on but what we're going to explore next time is meta prompts so we're basically going to get gpt3 to write our next prompts um and uh i know that that's a bold claim like like zaya said like borderline insanity um it is what it is that's what we got to do if we want to achieve general intelligence if we want to achieve artificial cognition that's that's where the order lies so anyways thanks for watching like and subscribe i hope you enjoyed this and found it illuminating um catch y'all next time