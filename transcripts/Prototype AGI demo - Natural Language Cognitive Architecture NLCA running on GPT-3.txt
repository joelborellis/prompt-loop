hello everyone david shapiro here with another video about raven and natural language cognitive architecture or nauka um i took a break for a couple months to write my book the book is now out you can find a link to it in the description below the epub is free um the paperback version is 7.95 i only make about 70 cents on it um yeah so here's where we're at i have created a few versions of raven now and the most recent one is based on open ai's gpt3 engine but i'm using the curie engine which is cheap and fast but it's not that intelligent so if you take a look at this real quick you'll see that raven is kind of um you know there's there's some good information you know i suggest you take the day off and relax that's great um and then i say hey raven i want to uh make a video about you what do you think about that and then uh the output is kind of weird um and then raven gets stuck on that which this is called what i call prompt contamination prompt contamination happens when gpt3 can't quite understand what the point of the prompt is and there's too much superfluous information so this basically means that i'm going to need to take a break until either da vinci is faster and cheaper or gpt-4 comes out so anyways let's see hey raven what is the future of the world if we invent nuclear fusion and i will show you all of the microservices that are running in the background in just a second um yeah see it it's confused so this is this is pretty much expected when you're using curie to try and run a full agi it's not quite there yet if i were to switch to the davinci engine it would be a little bit better and in fact davinci is the engine that i used for all the experimentation um in that in the book all the research code but i wanted to do a version in curie because one it's cheaper it's so much cheaper and so much faster and so it can still give you a proof of concept okay so you can see that raven is thinking it's not completely coherent and that's fine so let's take a quick tour of the actual files in this so here is the repository this code is is publicly available or at least it will be as soon as i publish this video there are a few python scripts and i'll show you each of these in turn i'll probably take a deep dive into the code in a separate video this is just going to be an overview and then uh so there's there's a few of the microservices and then um and then a whole slew of prompts i've got about two dozen prompts um that i'm currently using to run raven uh and then i also record every single interaction with gpt3 so you can see that raven is thinking there's a lot going on behind the scenes it's not just an input a prompt output raven is actually thinking quite a bit but again because i'm using curie uh it you know there's only there's only going to be so much quality that i can get i've kind of run into the boundaries of the technology today okay so uh let me go to actually okay sorry about that um this is the actual diagram the the architecture of what it's doing here um so i'm using discord as the primary interface discord has a great api it is it is a great platform for bots um and then you can also integrate audio later if you need to so this is the set of services that i've got running so first is the discord service discord service handles all of the communication with the discord api it also compiles the contexts so if you read my book or check out check out other videos there's there's what's called the context which is the input for nalco so it creates and handles the context it sends it to the outer loop service um and all of these use the the transformer service which the transformer service uh handles communication with gpt3 so it sends the it sends the chat logs to the outer loop which then uses communication with the shared database and the qa service to compose its corpus and then also to generate the output and again all of these services make use of gpt-3 so that's why gpt3 is in its own service so that everyone can communicate with it separately this also allows you to scale up very easily let's see then there's the qa service qa is is question answering not quality assurance so qa is question answering and in this version i have two primary methods that i'm using qa one is that i use qa to try and answer questions using episodic memories um or i just use the transformer because gpt3 has a lot of knowledge embedded um so basically what i have this this very naive qa service do what it does is it tries to answer questions um just by extracting information from uh from gpg3 and if it says i don't know then it will try and query the database to look for answers as well again this is all very naive this is just a demonstration level this is not an enterprise or commercial grade qa service this will require a lot of work but again the purpose of this particular instance is to show the simplest possible example this is more for learning and communication and demonstration rather than actually something that's going to be taken into production and then finally at the very bottom is the inner loop service which is actually generating most of these logs so there's a tremendous amount of internal thought going on all the time where raven is thinking about thinking about thought basically trying to extract themes of of the episodic memories figure out what to do about it and so on and again we'll get into a deeper dive into each of these functions in a later video right now i wanted to focus on the overview which is the architecture and how it works and also just show that it is indeed working um raven is not sick why would you think that let's see what happens i am not sick yes correct so anyways you can see raven is easily confused raven can't really keep up with stuff let me go ahead and cancel these services um let's see let's see this is the shared database service i have it using just sql lite um sqlite is uh is kind of the bare minimum that you can you can um run this on it's not the easiest thing to run it on but it is easy um it's not the best sorry it's not the best thing to run it on but it is easy and it's fast i have had much better results using solar and so the next version of of raven that i create will use solar as a microservice instead of sqlite but as a relational database this is going to be a little bit easier to understand let's see um this is the transformer service so this is actually handling all the communication with openai and you can see it running in real time raven is clearly thinking a lot behind the scenes and this actually gets rather expensive let me show you real quick how much how many tokens this uses so let's see i'm at six hundred thousand tokens um just running this this demonstration and doing a couple tests before recording this video um today alone and then that fortunately because i'm on curie it's uh it's only three point dollars da vinci is 10 times as expensive so this would be 36 just to run a couple of conversations so i mentioned in my book that that now ca today would cost more than a thousand dollars a month to run you could easily get to several hundred dollars a day because of how much it's thinking so that's why i needed to do a demonstration version on curie because otherwise it would just be prohibitively expensive to run um so yeah this is this is very expensive to run let's see this was the transformer service um let's see this was the database service um the qa service oh looks like i've got a bug in the qa service it faults every now and then there's still some bugs i have to troubleshoot um that's all right let's see the outer loop okay so you can see here's some information coming from the outer loop oh yep there was a there is a another fault i've designed it in such a way that it's actually robust against faults because you obviously don't want raven to just spit out error codes and that actually leads me to another thought that i'll address later which is basically that i believe agi is going to need some kind of proprioception so in the in the future versions of raven raven will actually be aware of these faults raven will say hey my qa service is faulting i need to restart that or i need to i need to troubleshoot that that actually won't be as difficult as you might think let's see and then we've got the discord service so this is obviously not running because i'm not typing in any messages and then finally the inner loop which is one of the busiest services so i'm going to go ahead and kill all those so we can stop burning we can stop burning tokens and let's go let's take a quick high high level overview of these of these uh microservices when i say microservices i mean microservices each one is is generally less than 100 lines of code or about 100 lines of code um so basically i just have this as a continuous loop this is the discord service so it it talks to discord and and it looks for incoming messages right now i've got just a few rules to determine whether or not raven is going to speak and before i actually had a prompt to determine whether or not raven was going to speak let me show that to you real quick let's see next speaker so basically what i was going to what i was going to use was actually use gpt3 to determine to all to predict who the next speaker was and this works on davinci but curie is not intelligent enough to handle this if you take the same exact prompt and switch between da vinci and curie da vinci performs very well on this um in terms of figuring out who's gonna who should talk next but curie can't figure it out so again i'm kind of bumping up into technical limitations of the technology today um so i switched from from using gpt3 to predict who's going to talk to just some basic rules it's faster quicker and cheaper i guess faster and quicker mean the same thing anyways so very very bare bones um uh uh microservice here um then let's go to the outer loop the outer loop is a little bit longer um now you see i've got i've got the the exceptions commented out because i was doing some debugging but again this is this is really simple basically what it does is the primary thing is that it takes the context um from the from the incoming um pardon me it takes the context from the discord service and then runs it through a whole bunch of prompts um to generate the corpus and then it also uses um qa right it uses uh it it uses qa to both generate questions and then also get the answers to those questions so that's kind of raven thinking behind the scenes and that's that's one of the reasons that you see so many so many logs being used so just running for a few minutes it was probably running let's see i was testing at about 10 a.m and then a little bit more testing and you see most of these were actually in the last few minutes as i've been recording this video um so it generated more than 500 interactions with gpt-3 just to handle the all the question answering and the inner monologue that raven has so once it does that it will it will compile everything into a corpus and then use the constitution and output prompts to generate that and let me go ahead and show you what those look like because showing you what the actual end product is will make it make a little bit more sense let's see there was a lot of thought going on so you got to scroll up and find a constitution and output there we go so this this is kind of the final product of the outer loop um so here's the constitution which is basically saying okay what do i think about this oh see that was not good i needed to add a stop there it didn't get that um oh this is because it faulted interesting okay so even though it was generating faults um it's still figured out it still got this far um i think this was caused by the fault in the qa service um anyways so yeah it's a little bit embarrassing that's okay uh the ultimate result is still the same scroll down raven says i am not sick um yep okay so by compiling these i know this is this does not this is not a good look um again this is this is a demonstration level version um and it needs a lot of help um i also need to to revisit the qa system um i had much better look uh luck on the qa system when it was based on solar um so let me go ahead and advance to that the qa service whoops let's see actually this video is getting a little bit long um well the qa service i pretty much told you what it does already basically it tries to answer from memory or it tries to answer um it tries to give a factual answer from gpt3 and basically in order to answer from memory it will it will pull the database for for a list of keywords it'll generate a list of keywords and and then search the the database for relevant memories and then go through and try and answer based on that this actually works pretty well when it doesn't generate an error i'll have to go and investigate that some but again i showed you in real time that it was able to integrate information so that's the qa service again less than 100 lines of code pretty simple pretty straightforward and then the shared database so the shared database can run on sqlite it can run on solar it can run on postgray whatever you want to do or postgres i don't know i've heard people call it either but basically this runs on sqlite and it presents um a rest api interface uh that allows it to do i give it a few functions one is you can just um uh select something so this will this will return a list um of of information um i've got it you know where where type is like one type order by and then limit um so that will give you this allows you to select lists of things and then increment so oh increment is a critical function because as demonstrated in or as i wrote about in the book you need the ability to update memories so every time you update a memory or every time you access a memory you need to update its last access time and its access count so that's where you see here i increment the axis count and i also set the last access time and basically this allows raven to keep track of how often memories are accessed there's a few reasons that you want to do that i'll go into a deeper dive in in future videos again because this one is getting to be a little bit long here's the transformer service uh i think this is the last one or actually no i need to do the inner loop transformer service it's super simple all it does is handle uh communication with openai i've got a few defaults set and a future version i'm going to make this a little bit more flexible so that we're not just reliant on curie with some of these some of these default settings again super simple micro service but by making this a micro service it allows you to switch to other transformers if you want to say you want to use a version of bert or gptj or whatever else you can you can you can replace your transformer microservice with any other transformer so let's say you want to switch from gpt3 to gpt2 you want to switch to gpt4 when it comes out you want to switch to another vendor you can do that by having it all distributed in this manner again super simple this one's less than 60 lines of code and then finally the inner loop the inner loop is is actually the largest and and most difficult um uh service because this is basically like raven thinking right this is raven thinking about thoughts it is very similar to the corpus in terms of how it is composed however i added this concept called chronology i found that it works better if you actually lay out thoughts in in sequence and so the chronology basically just says okay here's all the relevant memories to this current memory let's lay them out in chronological sequence and then see if we can draw any conclusions from it the reason from that is because if raven is thinking about an older thought raven might also have more recent memories um in order to see like cause and effect um so let's say you know you go to school or go to work you know a year ago something happened and then you get a follow-up event um and then you think about that you lay it all out in sequence and you say oh this is what happened right and this is all automatic in human brains right you you automatically your brain automatically gives you your whenever you remember something it kind of has a little bit of metadata attached to it um you kind of remember how long ago something was was it yesterday was it a week ago was it a year ago and of course human memories um are not are not that explicit like you might have trouble remembering was it four days ago or three days ago but you remember relatively how recently something was okay so this video is almost 20 minutes long i'll go ahead and stop it here this was just a broad overview plus a demonstration of raven and naoka or natural language architecture cognitive architecture i apologize thanks for watching and stay tuned for future videos have a good one