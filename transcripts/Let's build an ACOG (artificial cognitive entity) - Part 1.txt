good morning everybody david shapiro here for another video we are going to be doing an acog i've been talking about it for a while um this is not my first rodeo um i've actually written um a book about this and um basically over the last year since i um started working on that book i published it in what august so it's been about nine months since i published that book a year since i really was working on it um and i've been continuing to refine the process so let's let me just show you um what i'm talking about what do i mean by artificial cognitive entity acog or natural language cognitive architecture so i've got my book available online here this is the diagram let me zoom out a little bit so you can see it okay so this is it's composed of two loops there's the outer loop which deals with input and output that's interacting with the world so this is going to be the loop that controls like a robot or a voice or whatever microphone voice motors that sort of stuff and then there's the inner loop which deals with the mind and then the thing that links them is a shared database so this is really complicated a simpler way of representing it is this where you've got the inner loop which is thoughts planning memories etc then you've got the nexus which is the stream of consciousness or the shared database so functionally like okay say nexus that sounds complicated i say stream of consciousness that sounds complicated but functionally it's super simple um it's literally just a list of logs of of memories thoughts whatever um and they can all be represented in natural language so this is an example of the nexus right here this repo is not public but we're going to build a public one i have no idea how far i'm going to get in this video there's going to be multiple parts anyways so it's available natural language cognitive architecture i've got a whole book about how i came up with this there are lots and lots of diagrams about how everything works it's 100 free um and i've got all sorts of ideas about how how to build a consciousness how to build a an artificial consciousness so today all we're going to be focusing on is the inner loop and um and the nexus or the the shared database or the stream of consciousness i say nexus because it's two syllables it's easier to say um shared database is a little bit more concrete in terms of what it is um yeah so that's what we're doing um so this is the most basic architecture though and before we get started i wanted to actually talk about neuroscience so that way you kind of understand where i'm coming from and actually i forgot to grab the books before i started the video so let me go grab those books and i will talk to you about them as i'm talking about these architectures okay so i'm back with a stack of books and let me see if i can make this window bigger while i'm telling you about this does that work okay cool i think that worked um i'll leave that up so that i can see what's going on um yes it's recording okay so neuroscience books i started reading the telltale brain by vs ramachandran the telltale brain is a book about looking for what makes human brains distinctive in the animal kingdom um this book is phenomenal uh vs ramachandran is a great storyteller which which um he can he doesn't just like give you the facts like this part of the brain does this um because that's really dry but also it doesn't tell you what it means um he doesn't tell you the like if you just if you just tell the facts that doesn't give you the implications or the significance but by telling a story around each part of the brain and each like you know how he discovered something and how the tests are done you really get a sense of like okay this is how the brain actually works so telltale brain ramachandran phenomenal phenomenal book that one is is actually kind of what spurred me to work on these next levels of cognitive architectures on task by david bader i found the dust jacket i talked about this one in a previous video and i don't like dust jackets but it's pretty so on task how the brain gets things done um so this this book is about cognitive control another way of of talking about cognitive control is executive function so more people are probably going to be more familiar with the term like executive dysfunction which is common with um adhd and depression and other other things like that so executive dysfunction means that you're focusing on the wrong things and that you can't focus on the right things the the neuroscience term for that is cognitive control so cognitive control means like okay you're aware of what's going on and what you should be doing and and you have conscious ability to say this is what my brain should be focusing not this other thing so it's about impulse control it's about filtering it's about being self-directing um so yeah on task here let me just set this down um so on task is about how the brain achieves that and if you've done any work with large language models or gpt-3 you will know that it has no cognitive control so this is a huge thing that um that needs to be added in either more advanced neural network models um you know the architecture or it needs to be a secondary system or a a way of controlling what the model does that's really what we're going to focus on today because that's the breakthrough that i've had however i did also want to talk about a thousand brains so this this book also figures into the diagrams the architectures we're going to go over today um so let's see let me just have this up in the background um so yeah if you uh if you read this book base the the whole the whole idea is that the brain is made of repeating circuits that mostly do the same thing but they kind of vote um so there's kind of like a consensus about what they about how to decide what to do and i will show you how we can implement that soon we'll get to it today but very important ideas in terms of how do you design artificial cognition great book and then the forgetting machine so the primary theme of this book is just how little information your brain actually integrates the bandwidth between different sections of our brain is very very low and we're talking about like measured in kilobits a second not megabits or gigabits and so it's like okay well if you're only talking about kilobits a second is is our brain's bandwidth for like sensory input and and thought and output how do we get so much done right if if if our memories are very sparse right so to use um computer science terms our memories are sparse representations in that like if you were to represent it as a matrix it's mostly zeros with just a few values here and there it's like okay well how do we get so much done if our memories and thoughts and sense and sensations are all sparse um really good book this has also kind of reinforced my idea that actually we can represent all thought with natural language that's a perfectly good medium to represent what's going on in the head we don't need anything abstract like vectors although you can but the interpretability of using natural language is there um and then finally fandoms in the brain this was the my very first like neuroscience book um i read it or i saw i saw the documentary way back like 20 years ago um but yeah great book um both both of ramachandran's books that i've got here phantoms in the brain and um and the telltale brain both are look at it through the lens of neurology and neuroscience so you learn a lot about the brain when it breaks okay all that said let's go over some architectures make sure we get this out of the way so you can there we go okay you can still see me but you can see the screen okay so this is the most basic architecture where we've got the nexus which in this case the simplest implementation is literally just a folder of text files it's a list of inputs outputs thoughts sensations etc um and then the inner loop which in um in this one so basically what i was trying to do here is create a home home device that i could talk to the inner loop is literally just um one python loop um let's see which one was it i think it was this guy um well true yeah so basically here's the loop for for d and dossier list which the dossier list is just a list of prompts um do this uh so yeah that's it run the prompt load some load some uh well first i guess stack some memories load the prompt and then do it again so while true so here's one loop and then here's the nested loop um yeah that's what i mean by inner loop you're looking at it right here so we're going to recreate this but we're going to change it a little bit because of some of the insights that i had okay so this is the most basic model the outer loop i'm not as interested in robotics i used to think that i was if you want to know how the outer loop would look go look up google's flamingo um let's see google flamingo robot i think there's a good youtube video yeah researchers have developed a technique that enabled yep so basically um flamingo integrates large language models with robotics so i'm not going to be working on that this they got this handled right this is the outer loop where it's just how do you integrate natural language large language models or nlp and robotics that is what the outer loop is i'm not as concerned about that i care about cognition um okay so this is one possibility what are the other possibilities well humans as you may or may not know if you are a human who is watching this um we think that we have things like unconscious or or subconscious minds um and then when you look at other disorders like dissociative identity disorder um your brain actually can have multiple personalities in one head and so then there's like you've got your shadow self your super ego your inner child whatever you've got all these archetypes in your head so that indicates the possibility of multiple minds in one brain so what if you have instead of one nexus what if you have two what if you have your inner loop which is your conscious mind and then you have an unconscious loop that does like whatever our unconscious does so from a neuroscience perspective 90 of what your brain does is unconscious um so there's other stuff going on behind the scenes um and so this leads to a possibility where there's a second you know or more there might be there might be dozens or hundreds of little nexuses in our brains where thoughts are accumulated or or sensations or signals are accumulated and in fact if you look at the connectivity of the brain um it's a huge mess there are a lot of of little focus points concentration points where signals converge and then distribute again um so in order to create a full-scale brain or artificial cognition we're probably going to need multiple loops and multiple concentration points now if each if each concentration point is as simple as a folder of you know text files that's not that complicated and if each of these loops is only as complicated as a wild true statement and then a nested for loop that's not that complicated either so if if that if that's all that it takes to create you know a full sentient machine or a functionally sentient machine um that leads to some other possibilities so let's see like okay what if you have one outer loop and then you have multiple mines interacting with that outer loop so you know how if you get an impulse to like reach out for something and then something stops your hand so that in that that you're you you get that like arrested idea like where it's like okay i'm gonna go do this and then you stop yourself and you can feel like that cognitive dissonance in your head because there's you know there's the impulse to do something and then the impulse not to do it or the inhibition so that is where a thousand brains comes in so we only have one body to control but our brain has hundreds or thousands or tens of thousands of similar circuits all trying to figure out what to do so one possible architecture then is that we've got an outer loop but then we've got multiple mines kind of fighting over what to do and the outer loop basically takes a consensus that says okay you say we should talk i say we shouldn't this one up you know like if you've got three then you have a tie breaker so it's like should we grab that pot well you know two of them might say no don't it's hot and then the third one says oh go ahead and grab it it's fine right and so by having those parallel processes all kind of debating that gives you a bunch of possibilities these different these different inner loops you know primary mind secondary mind tertiary mind however many there are they should all be slightly different they should use different models different prompts they should use different different architectures so that one they can operate at different speeds but also they can have different specializations and different strengths and weaknesses and so maybe what happens when someone has dissociative identity disorder is basically they have the like their brain loses the ability to keep track of these different cells and they they fragment and differentiate um from each other um rather than staying integrated and so this is where um jungian psychology actually kind of comes back into play i'm really surprised more people aren't talking about jungian psychology because he talks about this fragmentation possibility anyways i predict that that's going to come back in a big way um you mark my words um okay so this is this is another possibility of how we can design an artificial cognitive entity in the future and then there's one last possibility what what what happens if we reverse this what if we keep one nexus but then we have multiple loops interacting with one nexus so in in this case each and every other case each nexus is only the link between two loops so it's like a figure eight right so this loop shares some information with this loop and so on and so forth and you could you could expand this out forever right where it's just every loop you know every intersection between two loops is one nexus um you see that's the same pattern over here you know this is the most basic unit and then here's where it's a chain right so you can create chains you can create webs but what happens if you have multiple loops interacting with one nexus so i got this idea from watching westworld so hbo's westworld is a show where there's robotic hosts and it's a big giant fantasy land and you can like have sex with super hot sex robots or shoot them or go on adventures with them or whatever but during the first season one of the things that happens is um they explore like okay well how do you make sure that the the hosts the robots don't break immersion and what happens is anything that they're not supposed to see is erased from their stream of consciousness so what happens then if you've got you know their their conscious loop but then you've got a hidden second loop that is that is monitoring that database and just selectively deleting stuff out of it so like oh you're not supposed to see that gone right it's that simple you just have something that says you're not supposed to see that you're not supposed to think that delete it and so that this model whoops come back this model could be used for um self-censorship right so say for instance you have a robot that um and it's got a safety loop right it's got it's got a self-censorship loop or a safety loop that says oh you just had the idea of stabbing your human let me just delete that possibility right and it's not even conscious it's a safeguard that's operating in the background and then you you'd have that interlocked so that if that loop stops the robot shuts off right so you have you have like multiple loops interacting with um with a single nexus and they could all be you know contributing or deleting stuff so that's that's kind of where i'm going i've got the books that inspired all this the show westworld that's a good that's a good bit of fictional inspiration um irobot the will smith movie from i think 2005 also good inspiration for this stuff okay now that you've got the background let's get coding so let me zoom back in a little bit um new so we're going to call this um a cog experiment 0-1 so artificial cognitive entity um public experiment um inner loop so public add a readme file add a license we'll do mit and then we will go ahead and clone this down and get clone whoops you need a space there buddy okay so then i i copy paste i reuse a lot of code um just that's the fastest way to do it uh let's see what was i working on most recently medical question answering so i will just copy my excuse me git ignore and my open api key open ai api key just copy those in okay so then we will start with i'm not going to worry about doing voice or anything um because that's my my smart home device was basically i wanted to have like the computer from star trek where you're just like computer can you help me do this thing right i wanted to create like a super sophisticated um super advanced version of like siri or alexa or cortana um and i was working on that but then i realized i needed to take a break and figure out cognition first um and then you know maybe once i get some help i can work on the the outer loop of you know because like one of the hard parts there there's a bunch of stuff that's harder than you might think like um you know alexa you can interrupt alexa you can say you know if alex is like yammering at you say alexa stop and it can stop itself right so there's some of that that inhibition um other people have already figured that out so i'm not gonna i'm not gonna retread that i'm gonna go i'm gonna go work on new stuff okay so we create our nexus which is where we're going to accumulate um thoughts and stuff so let's start with um we will go here um this is all older stuff so let me close all that um tell you what you don't need to see me do some baseline coding let me pause the video i'll get just kind of the basics going and then we'll resume the video and we're back i've written the script mostly i scraped together stuff from previous work again i recycle code no big deal there nothing surprising but let's go through it so that you can see this function so when i say like this is the whole inner loop you can see every bit that goes into it and then we'll get into some prompt engineering okay so at the very top um whoops save memory um exactly what it says on the on the tin it just saves you i pass it some some text and a label and it'll save it out to the nexus folder which will look very similar to uh to the to the memories folder here where you see it's got the timestamp prepended and then kind of a little tag just that way it's human readable to see like okay this is what it's about um there's a few advantages to this but mostly so there's a reason for this very early on in my research um i thought about like okay what goes into a memory or a thought or an idea and generally speaking there's a temporal component like if if i say like hey when was the last time you thought about walt disney world right your brain says oh it was around this other time you know so all of our memories are relative um we we have to kind of reverse engineer like okay how long ago was that but with computers we have the advantage of using timestamps and so all things that happen around that time are all going to be interrelated and so we can take a shortcut by using time stamps so we can say okay if you see hear and think something all at the same time they're all going to be related so like the input and output that happens in serial those are all interrelated whereas if you scroll down and say like okay well this output happened you know 3 600 seconds later that's an hour later so it's less likely to be relevant but also it allows you to rebuild a series of events later on so all the memories are going to be saved in sequential order like that so that's the first one and then second one is get timestamp which you just pass it a file name and it returns the actual timestamp i just wrote that as a quick function it's a quick reusable function not a big deal tempo so i use tempo to to basically say how fast this cognitive entity is thinking because if you remove this it thinks many many many times faster than a human can think so when i say like agi is closer than anyone realizes this is what i mean i have to artificially slow this down um so that way it can like even even if it's if it rests 30 seconds between loops it still thinks faster than you or i can um so imagine how much faster it gets if it if it can run multiple loops a second um or how much more powerful it can be uh yeah so i i hope that this video is kind of blowing some some minds and if it's not yet it will okay dossier list so i'm going to probably change this once we get to this but basically this is the list of cognitive tasks that are going to happen in every loop and the big insight that i've had is about how to do cognitive control also let me make sure that you can hear me or that i'm not blowing you up um okay i'm talking pretty loud and clear how's this uh okay that sounds like it's saturating sorry i tend to project a lot um i want to make sure you can hear me okay so basically this will be the list of of cognitive tasks that and some of them are our cognitive tasks that we wanted to do every single time so the insight here that i had is asking questions like what am i doing what should i be doing and what does this mean those those three questions need to be asked every single time and so for people with executive dysfunction their brain isn't asking that question what am i doing what should i be doing you know is this the right thing to do so basically what we're going to do in order to enact cognitive control those are going to be the first questions that this asks and then later on further down the stack once we get all the base all the boilerplate stuff then what we're going to do and i probably won't get this far in this video so to stay tuned but then what we're going to do is we're going to ask gpt3 to generate the next cognitive tasks so that's called a meta prompt where basically you use a gpt3 prompt or a fine-tuned model to generate a prompt for the future i've done this before with the core objective functions i think i've got it yeah i think it was my last experiment with the core objective functions so basically what i did was i broke it into three three parts so a meta prompt is basically where you say like okay i'm going to take the output from one prompt and use it to generate the input for the next prompt so what i did here was in order to enact core objective function three which is increase understanding um i wrote a prompt that i just you give it any particular scenario and gpt3 will generate a list of queries so let me show you how that works so write a list of internet search queries that might help gain relevant information for the following passage um and then for that let me go into let me just grab an older um we'll do a medical text let's find a smaller one come on i want one that's like one kilobyte there we go okay so this is what i mean by a meta prompt so i just say user rights shoulder pane blah blah blah list of internet search queries and davinci text of nco2 the instruct series is really great at this so basically it says like um okay what should i uh what should i ask okay so then if we go back to core objective functions and then we go to core objective function 3b answer the follow internet search queries as a detailed paragraph because provide specific information data and examples so this works because gpt3 already knows a lot so it it is its own source of knowledge all you have to do is get it out and so the first step is what questions should i ask and then it generates its own questions and so then um then the answer is like okay let's provide that answer so let's grab um shoulder impingement that's a good that's a good term okay so we'll say uh let's just stash that there oops and then grab this prompt so we'll say okay whoops okay so then we'll just do shoulder impingement and so then we'll ask gpt3 to just give a detailed paragraph of what this is shoulder impingement is a condition in which the shoulder joint does not move as freely as it should etc etc okay clearly it knows what shoulder impingement is so what we've done is we've first said okay based on this based on this medical situation that we had um let's let's look for some relevant information and then finally the third part of this so this is this is called prompt chaining where you have the input from one prompt or the output from one prompt serve as the input to the next prompt so on and so forth um so that's called prompt chaining um and then answer the following internet search queries as a detailed paragraph provide following information and examples um oh and then this one was just like add more information um that i so i added this as a third one because sometimes gpt3 will just give really concise answers so we don't need to do that one here anyways the point being is now you see what a meta prompt is where it's like okay i'm gonna ask you to generate something that i need to do next um and so that is once once we enact cognitive control those first several prompts that i talked about where it's like what am i doing what should i be doing how do i do it right those that's cognitive control then we're going to ask gpt3 to generate the cognitive tasks so that's where we'll get into metaprompting but we're not there yet we got a ways to go okay close that close that close that close that and we're back here okay so that's what i mean by dossier list i'll probably just simplify this to prompt list because everyone's going to know what a prompt is so in fact let's just go ahead and replace dossier with prompt we don't need to invent anything okay so we've got all the prompts listed this will be the second part of the video it might even be the second video because let's see how much how how long are we we're already 30 minutes in and we haven't even gotten started so we'll probably save the the prompt engineering for all the cognitive tasks later okay stack memories so the memories are going to be pulled from the nexus folder which i just created and so it's empty right but basically what this does is uh well first actually let's go through the main list i've given you the background so nexus index equals update nexus index so what this does is it looks for all the memories in here and it uses the gpt3 embedding endpoint to create a vector representation of every memory which allows you to do very easy searches so first thing is let's update our index or mental index that way we know what we know so this variable here the nexus index will hold everything um search index oh yeah and i'll actually have to add that here so first thing we do is whatever happened in the last loop whatever input or output or other loops are participating in the nexus let's update that index so that way we've got it in working memory we know what we know and and we can search it so then the latest just grabs the latest memories that's exactly what it says on the tin all it does is go into the nexus folder it reads the 10 most recent files so look going back to my previous experiment the raven one that'll basically be just like grab the last 10 memories okay that's the most recent stuff that's going to be the most relevant in the future we're going to want to be able to grab the most recent 100 memories 1000 memories million memories right but because gpt3 is limited in its window size i'm limiting it to 10. so it's working memory is very small compared to hours so in the main loop grab the latest memory then we stack the memories so what stacking the memories does is it just puts them all into one text block and it says like three minutes ago four minutes ago five minutes ago um that's all it does um so it just it just formats it into instead of a list of files it formats it into a list of text not a not a not a big deal oldest time um actually i'm not even using this oh yeah actually it's supposed to be used here so basically then what we say is like okay let's search so that your brain does this automatically this is all 100 inspired from neuroscience all the books that i've read um so once once your index is updated it's like okay great now what do we do we get all our latest memories so this is like the most recent stuff that's happened then we search for um we search for those um we've already stacked them um yeah so that's older stuff okay gotcha um so we what we do then is we search so the search index function comes up here and we just say okay take the most recent block of memories as a text pass the nexus index and so for every memory in here and there's going to be faster ways of doing this um there are there are like uh pine cone is a as a vector-based search engine um the work this is all experimental so i can hear some of you people saying this is not the most efficient way of doing it i know this is just for prototyping um ideally the whole search index that'll be its own api service as well as the memory so actually fun fact while we're here let me tell you something to do where did it go um raven so these memories one day will all be stored in a private blockchain so if you ever watch the movie um uh uh blade runner 2049 or whatever it's called um he has a companion that's an ai and her memories of him are private to that device so i'm like oh i bet you that's a private blockchain running on that device at least that's what my brain is filling in the blanks because the re like he says like download yourself into this device that way like when they come and grab you they can't find anything right because if you've got if you've got um so blockchain is really good because it is for sequential transactions and what we're doing with the memories with the nexus is we're building up a list of sequential transactions and if you have an ai companion that knows everything about you you better well have those encrypted if you value your privacy so anyways just wanted to point that out i have been saying that blockchain will be big for agi this is why is because you're going to want that nexus encrypted and but also not only encrypted a blockchain guarantees that it cannot be manipulated right so remember i mentioned the hosts in westworld where you just selectively delete memories you don't necessarily want to do that because imagine you've got a super powerful agi that's in control of like military tanks you don't want to selectively delete memories like you want it to be accountable you want it to have a cryptographically guaranteed logical sequence of memories um okay so that's all relevant again this is all purely inspired by neuroscience oh fun fact so people with particularly narcissism and a few other personality disorders or mental health disorders their experience of time is not linear um you the the term flashback so ptsd is another example so what happens with a flashback whether it's an emotional flashback or an acute flashback is that your brain shifts back in time to the last time that something happened and so like um they explore this with uh bernard or arnold whatever his name was in um in westworld where his his time indexes are all off and so he's keeps from his perspective he keeps jumping around based on whatever's happening right he doesn't have a linear sense of time and that can be what happens with ptsd narcissism and other disorders where your brain like is so fragmented that like different parts of your consciousness exist in different times so that's another reason why one we want every memory time stamped and two we want it cryptographically verified in a blockchain okay getting off my soapbox all that this does is it searches the index based on a search query that you put in it says find relevant memories so that's all it does this is a big long function it just looks for similar memories i've got a really simple function here it just gives you the in the dot product of your search your search vector and then of the memory that you're querying and so it just says okay what is the similarity between what you're searching for and this other memory your brain does this automatically um what is the term for that there's a specific term um like association right um your brain associates memory so like for instance i'm at home right now so my brain has a whole bunch of memories associated with home um and this so that is actually why you forget what your what you came into a room for because your brain says oh the settings are different so let me let me grab a different set of memories and then you go back where you were and you remember again that is that is what's happening in the background um in real time so again i didn't invent any of this stuff i'm just copying what nature figured out with our brains um so search index and what this does is i just say okay give me the five most relevant memories to whatever is going on right now again ideally in the future this will be 5000 memories it'll be 50 million memories because we want our agi to be smarter than us but right now we're limited by the size of the payload that gpt3 can take okay so then we stack those memories as well so we have the latest memories that are stacked and the older memories that are stacked so that's long-term and short-term memory again i didn't invent any of this stuff i just copy-pasted it into python so then what we do is we go we go through that list of cognitive tasks so the first part of this loop is going to be let's just add a little hashtag this is going to be this is going to be cognitive control loop and then so this each of these prompts is going to be stuff like um what am i doing what should i be doing should i be doing um uh how should i do it but also what should i be thinking about that that is so that's metacognition so what we want is we want this this machine to not only think about what it's doing but what it's thinking about and then provide that answer and then think about it um i've already done lots of experiments gpt3 is really great at these kinds of tasks like i said i'm not going to get it to it in this video just want to like wet your palette but what should i be thinking about and then other things like what are the implications here so like for instance if um if you're driving a car and someone pulls in front of you and like you're going 80 miles an hour and the other car is going 10 the implication is you're about to hit that car right so we want we want to be able to anticipate what are the implications here um so we'll call this anticipation because your brain will automatically anticipate things so we these are these are things in the cognitive control loop that's all relative relevant information that you want to be present in every single loop um and so then another thing is um the core objective functions which so this is this is the steering the moral steering of the ship that i've talked about so my heuristic imperatives which are you want it to reduce suffering increase prosperity and increase understanding so you want your agi to be thinking about these things every single time you don't want it to selectively choose to be moral or not you want it to be moral every single iteration okay so this is the cognitive control loop and then so then we'll do a second one um uh one of these things will will be generating tasks so basically we're going to say like um cognitive oops cognitive tat whoops sorry i really hurt my pinky i was building a retaining wall and it got smashed between two two ninety pound blocks so that's why i'm making more mistakes than usual when i'm typing excuse me equals list so one of these things here so to do to do is um you know cognitive task equals generate you know new task i'm so sorry my typing sucks right now you don't realize how much you use your pinky until it's like bruised down to the bone um generate new task and then you say like uh to do to do um cognitive tasks dot append cognitive task okay so that's in the to do so then you'll say like for task in cognitive tasks and then we'll basically do the same thing to do execute cognitive task okay and then you get to the sleep which is uh the tempo so right now i've got it set to 30 seconds this is still going to think way faster than you or i can think um you'll be shocked when you see how powerful this this architecture is okay so there you have it um 141 lines of code uh we have the the bones the framework of the inner loop of our artificial cognitive entity or acog or ace i like acog because it's two two syllables so like ai that's two syllables um whereas you just say ace that's like ace what um all right let me go ahead and stop the video here this was a lot probably like drinking from a fire hose it's already 42 minutes yeah this is this is on the long side and we haven't even we haven't even run anything yet um all right so thanks for watching stay tuned for part two part three whatever is coming and um yeah like and subscribe