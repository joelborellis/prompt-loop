morning everybody David Shapiro here with a video about robotics let me kill flux there we go um so today's state of the industry uh update is going to be about gpt3 or large language models in general and Robotics so the first one I want to introduce is say can so say can is what does it do as I can not as I say this is a an experiment to integrate uh robotics with large language models to perform the planning and actions and so the key thing that they've done is they use large language models to plan actions and figure out what it can do through affordances and waiting I'm not going to go through the whole paper but I'll just kind of give you the high level things and you can see it kind of doing its thing here in the background their um their page this link will be in the comments um it's great it walks you through the whole thing with demonstrations and examples and it's wonderful you even see it from the robot's perspective it's pretty cool um so yeah this is this is really great I predicted that this would happen back when I wrote natural language cognitive architecture and it was not long after that they uh started doing this kind of thing so basically this is a very early realization of of you know I'm not I don't know I don't know if they took it from my work but it is it is a natural language cognitive architecture it is using natural language to think um and plan um now one thing that's missing from this is that it has no moral affordances it doesn't think about what's right or wrong it's just doing a task um and this is that is by no means a criticism against this work this work is phenomenal it's setting the stage for future things because eventually one of the one of the things that you'll have to create weights or values for or affordances is um is something dangerous right is there high risk is it low risk is it morally or ethically ambiguous is it objectionable um but by by trying to assign numbers to things um that like that's that's how you get started and there's plenty of other things within affordances that have nothing to do with moral or ethics you can calculate Things based on how much time it's going to take right so time is a cost energetic expenditure is a cost how much money is it going to cost right there's all kinds of things that that our brains assess the cost and and like reward cost risk um and and benefits um all automatically very fast um anyways so this really sets the stage I'm excited to see where this team and people who take this research go with it um I definitely recommend you check it out they have a simulation version so you can just download it and run it yourself the other thing is uh uh this company engineered Arts they have uh integrated gpd3 with their robot platform so it can have open-ended conversations um I'm not going to play the whole conversation for you um it's very clear that it's it's using just kind of some basic gpt3 prompting so that it can respond to any question um I don't know how much they have solved in terms of long-term conversations um but hey if they see this video I'm happy to talk to them um and and talk about using semantic search for uh for holding long-term conversations although I'm sure other people are figuring out long-term longitudinal chat Bots what's going to be interesting is when you have humanoid robots with long format conversations and cognitive architectures for solving problems and following instructions that's really like kind of what we're moving towards and the Tesla bot you know that's that's what they want to do so Amica is the name of I think that's the name of this this chassis um uh but the the the company is engineered Arts so you see they've got their their robotic chassis it looks it's kind of in The Uncanny Valley of of human forms right uh especially because it's got this kind of like slightly curvy body like almost organic to me it's a little bit unsettling um but you know it'll take some time uh it is still very impressive just how sophisticated it is um you can even just kind of zoom in and look at the um look at the the I don't know if it's pneumatics or Hydraulics but it's it's got connection points in similar locations to where human bodies do so the particularly I'm interested in these long ones that connect to the to the bottom of the arm because we have really long muscles that connect here and actually um if you pull down it engages all the muscles um in your ribs as well and you can kind of crunch up your whole body um I did an experiment years ago where I was trying to make um like complex joints with cheap parts it's called Murphy I think I've still got it down in my shop maybe I'll post some pictures of that um anyways it was not going to work uh because I couldn't figure out the musculature someone did recommend pneumatics anyways I'm drifting I'm getting off topic um so yeah just wanted to show that say can this came out um just a few weeks ago I believe um let's see their update as of 8 16. um okay so the initial release was back in April then last month they did a bunch of open uh updates rather and then this was just just released just a few days ago so we can see that there's progress happening there's multiple uh folks working on integrating large language models with robotics the future is coming faster than you think I am telling you guys like yeah we might not have like AGI solved but as many people actually have commented on Twitter and other places we don't necessarily need full AGI before these things are one useful and too dangerous um you don't need something that is super intelligent um in order to put you know something like this inside of say for instance a combat drone or a domestic like you know make a slightly smarter Roomba that you can talk to um so basically kind of what I'm the the conclusion that I'm coming to and this is not like this is nothing special but is that uh AGI will be realized very slowly and in degrees and this is why I started talking about artificial cognition is the goal is because this is a machine that thinks it thinks about how to solve a problem that you gave it it only does that one thing but it's thinking and so then then the problem is how do you make it think more how do you make it smarter or faster how do you make it able to solve more problems right so this is a natural language cognitive architecture It's A Primitive one but it's darn good and then this guy over here the Amica robot I don't know how much cognitive architecture is in it but they're integrating it with a robotic Opera operating system and so they're working at it and I think that I think that history will record the the deployment of large language models like gpt3 like Bloom like Lambda history will record this as the inflection point where we actually solve that General open purpose uh general purpose open-ended Computing because that's really what it does um with with the with the Advent of large language models we now have um open-ended Computing so what I mean by that is you can have a system that just it'll keep thinking and it's not a finite State machine it's not an infinite State machine where you know it's moving from one mathematical state to another it's completely open-ended in my other experiments um uh get oh there we go um so I I'm reorganizing it so I'm uh I've got I renamed this one um the longitudinal study so this is this was the experiment I did a few days ago where I'm testing core objective functions for their um for different different paradigms for their longitudinal stability um and I showed that Foundation models like Da Vinci tend to be unstable whereas uh fine-tuned models like instruct series tend to be stable but less creative everyone knows that um so I just demonstrated it in a different way anyways so you know what am I trying to say I don't know it's it's just very exciting and I I'm curious to see how all this work comes together on um robotic platforms obviously AGI does not need to exist in a robotic platform that's just going to be the thing that you interact with personally I suspect that um the most powerful things are going to run in data centers in the cloud and you're just going to have a terminal just an endpoint right like you're going to interact with it through your phone through a smart home device but its brain is going to be running up in the data center and I mean that's that's how gpt3 and other large language models run now they're too big to run at home you actually need like several very large computers to run them anyways so that's the state of the industry update is we've got this very exciting time where large language models are being integrated with robotic platforms so we will see where this goes stay tuned it's coming fast thanks for watching like And subscribe and consider supporting me on patreon have a good one