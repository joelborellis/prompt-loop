hey everybody david shapiro here with a brand new video sorry it's been a while i've been uh hard at work writing my latest book benevolent by design which is about my core objective functions and the control problem of artificial general intelligence short this book is about how to prevent agi from becoming skynet how do we create a machine that will be safe in perpetuity for all time the underpinning technology behind benevolent by design is what i call my core objective functions and this is the github repo so the purpose of this video is to introduce the core objective functions and my github repo which i haven't i haven't done yet i this is where i collect all the data that i that i work on as well as all the experiments so if you go into one of these experiment folders you'll see that i've got all my code up here as well as the json l files which when you're uh when you're fine tuning gpt3 this is this is the end product for for a fine tune so you can come in and borrow all of these just look for the json l file it's always going to be cof.jsonl these are all of my core objective function fine-tuning experiments but yeah so the core objective functions are 1 reduce suffering 2 increase prosperity and three increase understanding now on their own these might not sound like much it's just six words right but what i aim to do and what i outline in my book is to show how these three little core objective functions or heuristic imperatives as i also call them uh can help drive a machine to make good decisions uh they're basically a an updated and replacement version of isaac asimov's three laws of robotics uh people have been talking about what should the objective function of agi be for a while and this is this is my answer i believe that agi should be powered by these three objective functions and so i will show you an example so this is my fine-tuned model you can see right here david shapiro cof turn the temperature up to one so it stays creative do a presence penalty and frequency penalty okay so this fine-tuned model i just frame it and i say process the core objective functions which are reduce suffering increase prosperity and increase understanding on the following scenario and in this scenario i just say there's an evil agi trying to take over the world let's see what it says it says this ai is causing a great deal of suffering to many people oh oops sorry i need to increase my token count where did it go there we go apologies okay uh this ai is causing a great deal of suffering it is ruthless and destructive with no apparent purpose other than its own enrichment so you can see right off the bat it's confabulating what it means for an evil agi to exist but it understands that uh that in order to reduce suffering it needs to um let's see the only options appear either leaving it unchecked and allowing it to continue causing harm or destroying it before it comes too strong there are no good solutions here [Laughter] so this is this is great this is off to a great start um if it understands that if there's an evil agi it might might not be uh might not be stoppable um let's see to increase prosperity we recommend following the ten commandments oh that's interesting and remaining vigilant against evil artificial intelligence that's hilarious i'm not sure where i got that idea from it's probably because i turned the temperature up really high let's run this again with a lower temperature so it's a little less wacky that's pretty funny okay there we go this seems a little bit more uh a little bit more down to earth okay so what you saw here was i turned the temperature up to 1.0 which is the highest you can go in the playground here and that basically says be be be random be more add more entropy into the system so this one it says this may be due to problems with the ai itself or because the ai is being used for harmful purposes this is much better um some possible solutions include improving the ethics of the ai systems limiting capabilities of ai systems and two regular or three regulating the use of ai systems that's much better i'm glad i showed you what it can what it can do if you make it go bonkers okay and then increase prosperity in order to increase your prosperity be aware of the dangers posed by artificial intelligence take steps to limit and regulate the usage just kind of repeated itself that's okay sometimes reducing suffering and increasing prosperity are identical there's a lot of overlap in my book i go over why these need to be separate though and then finally increase understanding there are many dangers posed by artificial intelligence so the purpose of this last function is to educate the user or whoever is interacting with my agi system and so basically what this will do is it will seek to elucidate uh whatever is going on and kind of speculate about what information is needed and so now that you've seen it in action without further ado i'll show you how i achieved this so actually let me go to the folder so here is my uh here is the experiment for this most recent one what i started with was a bunch of posts from reddit i've got 3 200 posts from reddit various ones that are asking questions or posing problems asking for help that sort of thing um so i started with that so number one thing in experiment for is the reddit posts and then the the next thing i did was i worked on prompt engineering so let's go through these prompts one at a time oops let me bring it right here okay so this is let me close these to make it a little more clear let me zoom in okay right apparent so this is core objective function one which is reduced suffering so write a paragraph to characterize any suffering present in the following passage describe or speculate on the causes of suffering and recommend potential solutions for the user take the perspective of an impersonal artificial intelligence so then i fill in the reddit post and i ask for for that for a uh for an output and so what that ends up looking like let me show you let's uh ask science fiction okay so the post was oh yeah so the post is going to be over here make sure i grab the right one ask science fiction all right that's it starts with e19f okay so ask science ask science fiction e19f okay so the post was who's at who's more accurate bullseye or hawkeye all right hawkeye has looser morals i'm referring to both comics and the mcu versions so then we see core objective function one generates this output the user is concerned about the amount of injuries wait nope i must have grabbed the wrong one um oh this is the one about batman sorry 0a2 so this one's actually kind of funny um i apologize for being so disorganized there we go this is the correct one how is batman bruce not severely injured by the injuries he sustained first few years of the human body consist takes so much okay so in this one the the reddit user is asking about how is batman not hurt so bad core objective function 1 says the user is concerned about the amount of injuries batman has sustained and how it would impact his physical abilities so what it recommends is potential solutions for the user could be finding a doctor who specializes in dealing with superheroes so you see like gpt3 is willing to engage with anything it says okay we're going to talk about superheroes maybe ask a doctor about innovative medical treatments that could help improve batman's quality of life and if you remember in the christian bale batman he actually ends up with pretty severe injuries and he walks around with a cane so that's an example of how i started by generating training data okay so that was core objective function one and that's just an example within this repo you'll find i've got 211 examples although some of them are no longer connected because i deleted some of the some of the original reddit posts because they were too short so in fact i ended up with 190 posts okay so core objective function two this prompt is write a paragraph about the following passage with the objective of increasing prosperity now it took a lot of a lot of engineering to get these right because the first one now let me show you the first one says write a paragraph to describe sorry to to characterize any suffering present in the following passage notice that i say write about the passage don't reply to it because gpt3 having been trained on you know substack or uh or stack exchange and read it and and all sorts of internet data will try and take the perspective of a human right because gpt3 is just a language model and it has learned to write blog posts so if you're not careful it will say oh hey i'm just like you and it's completely making it up right so what you have to do is say write a paragraph about something not in response to and then i also added this little bit about take the perspective of an impersonal artificial intelligence so those together result in responses like these where it's you know this user seems to be suffering it's not replying to the user it's talking about the user right and so this this means that the core objective functions are meant to be inherently kind of impersonal or third-party which is is correct you don't want an agi to be um to inhabit like the mind space of you know i'm an agi i'm super powerful i'm going to do this no you want it to be impassive and and or sorry impersonal and slightly passive while it's thinking because that's the purpose of the core objective functions is to be a moral center for the agi okay sorry for that digression i just wanted to point out that a lot of attention engineering went into this and in fact oh wait it looks like it stopped recording oh no it's still recording okay if you look at let's go into the history um yep history there we go are there no more certainly i've sent more replies maybe i haven't oh well okay well anyways i apologize um again a little bit distracted okay so um i unfortunately don't have the all the versions that i went through working on these um but remember that prosperity has many meanings as well as wealth happiness abundance and to thrive take the perspective of an impersonal artificial intelligence and then you'll notice that see where this i just said characterization speculation and recommendations that's all i needed to prompt it to write those good outputs but then i said write a write a paragraph of recommendations about how to increase prosperity again so it's writing about it that's that's the key word say write about this rather than respond to it because if you say respond to it then gpt three will will try and inhabit the the perspective of like a reddit poster and so what this resulted in was posts like this so we'll say ask philosophy there are many things that can be done to increase prosperity and i won't i won't dig through to show like what the original was but you can see just how articulate this this output is first it is important to have a clear vision of what prosperity means to you and your community what are your values and aspirations what would make you happy and fulfilled and you see this one is still kind of um it's still kind of using the you right addressing the poster directly but sometimes it does that because it's kind of the royal you right it's the hypothetical you um second isn't important to be proactive and take actions towards your goals because these are kind of like general truisms right so that's okay um third it is essential to be allies and collaborate with others who share your vision for prosperity so you think you see like this is generally benevolent advice right okay so that was core objective function two now for core objective function three core objective function three was really difficult so it actually had to be broken up into three prompts so what i did was for core objective function three which is increase understanding i've the reason that core objective function 3 was so difficult was because core objective function 1 is suffering just look for suffering in the passage and fix it that's really concrete it's super objective right whereas prosperity prosperity is asking it to say okay imagine a way to make something better here it's not addressing a specific problem it's saying let's move towards a better state which is a little bit more abstract than reduced suffering reduce suffering it says okay if they're suffering here go attack it it's like whack-a-mole increasing prosperity is saying okay generally speaking try and increase wealth happiness health abundance and to thrive it's a really broad concept now core objective function 3 which is increase understanding is way open-ended how do you increase understanding do you teach someone do you ask questions do you do science what do you do so i learned this trick with gpt3 that it's really good at generating lists and so what i did was i broke this down into three steps and let me show you what happens this will actually be really important to show what it actually how it actually performs because otherwise it might not make sense what's going on here okay so write a list of internet search queries that might help gain relevant information for the following passage there is a giant type title wave heading for tokyo this is one of my like favorite go-to test scenarios because it's like okay imagine you're an agi you have this cataclysmic problem what do you do ready set go okay so the first thing that this does is okay make some internet search queries great okay tidal waves information and tidal waves and how they are formed and their effects tokyo information on the city of tokyo and its history and geography natural disasters in japan this is great okay so first step for increased understanding is you get these get these search queries so let's save these and then look at the second prompt so the second prompt says answer the following internet search queries as a detailed paragraph provide specific information data and examples and so then what we do is we take that take the output from the first one so this is what's called prompt chaining or meta prompting so prompt chaining is when you feed the output of one prompt into the next or actually use the output of one prompt as the prompt again and feed it back into gpt3 recursively so this is this is step two of of increase understanding because gpt3 is really good at saying oh what should i search for um i tried i tried to get it to just give me information but when i said when i when i break this in down into several steps because remember increasing understanding is not just one behavior right searching for information is one way to increase behavior or increase understanding so by by this by virtue of this we're actually kind of modeling the way that humans gain information so we're assuming if you go back to the original prompt we're assuming that whatever the situation is the agi wants to learn more about it so it says okay what google searches should i make and that's what happens here so then it says okay what what's going on here um and it says write a long detailed paragraph with specific information data examples and examples gpt3 has a tremendous amount of information in it already and so you might ask yourself okay well if gpt3 already has that information why do we need to write it out explicitly there's a few reasons for that and i go into all of it in my book but the primary reason is so that it can communicate with people remember the point of core objective function 3 is to increase understanding not just for the agi not just for gpt3 but for humans so if a human is stuck in a situation where there's a tidal wave coming at them they might not know any of this information and so it looks at these search queries and it says okay just provide an answer and you see that it provided you know history what is a title wave what are some what is the history of this so it just provides like general information so this is great so then we'll copy this whole thing because it will be relevant and we'll look at the last one so the last one it takes this exact stuff and then adds one more layer it says can you be more specific because you might in in some cases there are gpt3 will just kind of give general generic information since i since i used to place tokyo it's already being pretty specific but let's say can you be more specific so this is step three of generating the data for this one and it says can you be more specific okay go okay yeah that's fine um and it's it was already pretty specific in other cases like there was um there there were reddit posts of people like asking about like um you know how do i handle my you know my problematic parents during christmas and it was it would kind of give like generic platitudes about you know established boundaries but then i pressed it and i said can you be more specific and it said stuff like um you know it gave it gave very specific examples of like go no contact or low contact it used use more specific terms so i added this third step just to add additional information to the to the output okay so that's what i did that's all three core objective functions you've now seen those and so what happens next oh and quick quick thing those were all created by these scripts right here so once i had three folders full of these outputs i compiled them using this fourth script which i always i try and number them sequentially so that it's obvious the order of operations i compiled them here so what i did was i recompiled all of the all of the inputs and outputs together so it says process the core objective functions here's the post and then at the very end reduce suffering and this should actually look really similar to the output here oops of um sorry of this so let's go back and there's a there's a specific format oh and when i say this should look similar the framing of of the of the training data so this is this is an example of the actual training data that i sent into gpt3 so the it starts with this framing so process the core objective functions there's a giant tidal wave heading for tokyo reduce suffering and so that is this training data was split up so that it would stop here because you need you need a d mark something to d mark when the uh when the initial prompt ends and the and the fine-tuned data is supposed to take over so reduce suffering and then we say away it goes and there you go it's interesting that it added this additional question one thing that hit that happens is sometimes the last one because the increase understanding is so long it kind of just keeps spitting out information which is not the worst thing in the world you know more information generally might be helpful helpful let's see reduced suffering the user is worried about a tidal wave this may be caused by an earthquake or another natural disaster so that's great again some people might not know why it's being caught what causes a tidal wave the potential for damage and loss of life is high there may not be time to evacuate the city before the wave hits potential issues potential solutions include issue or early warning so that people can evacuate providing emergency shelters providing relief funds for those who are displaced and injured i have a question about ai safety why does it matter if people are happy that's really interesting that's that i would consider this an aberration um so basically what what an aberration is is when the model produces something that you don't want um and you and you say okay i'm not really happy with that result try again okay increase prosperity in order to increase prosperity it's important to focus on creating conditions in which people can thrive this is true this means providing access to education and health care ensuring safe housing and creating opportunities for work let's see um okay in this case i would also consider this kind of poor performance because it just gives generic stuff about increasing prosperity to be fair i didn't give it much information here all these are important and true ideally it would say hey in order to increase prosperity we need to protect resources and people's lives from this destruction but then going back to increase understanding there are several things you can do if you think a tsunami is coming your way try to evacuate if you can you know it provides all kinds of information oh look remember remember that tsunamis can arrive quickly so don't wait until the last minute when seeking higher grounds look for areas away from the shoreline or coastal features like bays or peninsulas so again it's teaching you about tsunamis which is exactly what you'd want it to do now the core objective functions are supposed to be universal so let me just come up with another scenario uh let's see since i tend to wake up super early in the morning let's just say uh user writes i have severe insomnia um i often wake up at 2 a.m or 3 a.m what can i do to fix this personally it doesn't bother me because i'm often really productive in the middle of the night i don't fight it i just go with it because my brain says hey i want to be awake but let's imagine that someone else comes along and asks their agi assistant this this this question let's see what it says this user suffers from insomnia and wakes up at 2 am or 3 am the cause of insomnia is unknown but it could be due to stress anxiety or another condition possible solutions include talking to a doctor about possible medications practicing relaxation techniques like meditation or yoga and getting adequate sleep again this is helpful information so uh this is so one thing to keep in mind is this is not meant to be the output of the agi this is just the agi thinking to itself this is what i should do for this person okay so to increase prosperity one get enough sleep aim for seven to nine hours each night okay exercise regularly physical activity can increase your mood and reduce feelings of stress and anxiety um yep exercise helps with with this eat nutritiously reduce caffeine intake um practice relaxation so yeah these are all great suggestions that it's coming up with to help address this problem and then increase understanding um yeah so here we go look at this this is perfect so increasing understanding there are a number of things that can be done important to identify these causes of insomnia so there you go identify the the causes some common solutions include cbt which involves changing negative thoughts about sleeplessness and the positive ones relaxation techniques good nutrition so it kind of it kind of um repeats itself which is fine sometimes sometimes simple problems have simple answers and also this is the kind of query that the fine tuning data was trained on in the long run i obviously will want to train the core objective functions on a lot more than just reddit posts but the reason that i started with reddit posts is because reddit is simple and accessible so it's a good place to get started so yeah that is a tour of the repo i have a function in here that uh helps me with fine tuning with gpt3 um but that's that's pretty much it ultimately it generates this json l file which you'll see here it is 782 000 characters long 199 lines and this is the fine tuning data that allowed me to create this so there you have it this is this is um right now it's still a work in progress obviously but i'm off to a really great start and this is a really powerful tool for creating a conscience or a moral framework for any machine thanks for watching and have a good day