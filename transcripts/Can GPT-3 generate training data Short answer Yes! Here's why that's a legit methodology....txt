hey everybody david shapiro here with a video um i know that i did say that i'm taking a break um from research but apparently i'm getting back into the groove of making youtube videos so there was a discussion on the open ai forum um this guy he saw my video about reducing confabulation and he had some questions um and so first i just wanted to say that like if i have not been as helpful of as an educator as some of you would have liked that's my fault because i was primarily using youtube as a mode of dissemination um but uh and this probably seems obvious to other people um basically what i'm doing is i'm trying to teach people what i have learned and what i have discovered but to me it was like i didn't connect the dots right and i don't even know why because i i do uh training and teaching and mentoring and professionally in my day job so anyways uh i just wanted to say that like i am learning to put on my professor hat you can see like i'm dressing the part better and um i've moved into my own office um in my house i'm getting it all decked out so uh yeah so practicing putting on my professor hat um i don't do teaching full-time uh so i'm getting used to it anyways so he asked this question very salient question can gpt generate its own fine-tuning training data a lot of my videos i do what's called synthetic data uh and so basically what what synthetic data is and i've got a few articles up here i'll put them all in the comments just can gpt3 create synthetic training data for machine learning models the short answer is yes many of my videos i demonstrate how to do this and then here's a forbes article talking about synthetic data is about to revolutionize artificial intelligence here's an nvidia article talking about the same thing that um synthetic data with transformers is gonna you know is good for enterprise um and this was may 9th so this was a month and a half ago and then finally um towards data science article um just over a year uh almost a year and a half old about synthetic data um yeah so i just wanted to say that if you if you have seen all the videos that i have shown where i used gpt3 to generate its own training data for fine tuning models um that is a legitimate practice it does have its own pitfalls and uh and strengths though um and so going through this um there was there so the the first thing is like okay why what's the benefit if you're just using one model to generate output and then fine-tune the model what are you actually getting out of that um and so i wanted to um kind of go over kind of the the the top level reasons even if you don't use much different data um there's a few there's a few benefits so first of all when you generate fine-tuned um or fine-tuning data or synthetic data with something like gpd3 you can filter out the ones that you don't like the samples that you don't like so that you can get a more consistent model and we'll get to that in a minute like what do i mean by consistency um that's the question of precision versus accuracy but then there's also the problem of confabulation or hallucination in these models and we'll get to that as well so then another advantage is that you can incorporate multiple prompts so for instance rather than just have one prompt you can have data that is several different prompts either stacked right where you have meta prompts or prompt chaining to generate the output um or you can have you can go more more lateral scaling which by that i mean you can have multiple different types of problems in your fine tuning data i've demonstrated that in my core objective functions fine tuning videos where i actually train one model to do three different tasks so you can either do different tasks like go sideways where it's like task one task two task three and you have one model that can do all of them and also this chair is squeaking let me let me swatch swap chairs real quick sorry okay sorry about that i got a ten dollar chair used chair just to see like okay if it works it'll be good but it was squeaking so it's no good um ten dollars wasted not a big deal okay sorry so um so yeah when you when you do synthetic data with gpd3 you can incorporate multiple prompts and and that means that you can either do prompt stacking where you generate data that requires multiple prompts to generate the the input and output or you can do multiple tasks or both um in my core objective functions let me actually show you core objective functions in experiment four i actually had to use um maybe it wasn't this one oh yeah so in this one i actually had to use i i did both so this one is trained to do three different functions three different tasks which is reduce suffering increase prosperity and increase understanding but to increase understanding to get that synthetic data it actually took three prompts most of it was just the first two prompts but the point is is that i i basically trained one model to do five different tasks all all in one so that's another advantage of doing um of using uh fine-tuning uh gpt3 with its own synthetic data is you can kind of compress different problems into one model and in their documentation openai said that that doing this actually tends to increase the performance of all so you get some transference effect where um the the bigger your fine-tuning data set is the better performance that you get overall um let's see and then finally you can incorporate um lots of different data so if you don't if you do 100 synthetic data um which this is not so in this one i had um i had some real world data from like reddit um which is so that's not synthetic at all but in my chat bots um that i did those are um those some of those are 100 synthetic um let's see let me swear did they get one um actually the movie script generator because in this one the premises were all generated by gpt3 as well right so this is 100 synthetic data where the input that i generated was synthetic and then the output was also synthetic um so the chatbots that i've done the movie script generator those are 100 synthetic but other ones if you take real world data to generate or for the input and then only the output is synthetic then it's only 50 synthetic um so i just wanted to to clarify on that point as well so going back to here um yeah so you can you can have different data sources as well and one thing that i found so um i realized that i don't think i've ever actually said this so here's me putting on my professor hat this is why um this is why i like having different data sources is because um and i actually discovered this with the core objective function experiment where if you go to where was it here we go um so the original one uh oops that's not what i meant to click on core objective functions experiment one there we go um so what i did here was i had 50 000 different contexts that i could pull from some of them were dialogue some of them were reddit discussions some of them were stack exchange questions some of them were news articles right and so it's not just having one type of input data i actually have different types of unstructured data going in and so when you fine-tune or when you generate synthetic data to fine-tune with entirely different structures of data because like a dial you know a dialog is one format of data a news article is another format a reddit post is an entirely different format so by showing by fine-tuning with different kinds of input formats you get the model more robust so it can generalize and say okay whatever whatever my input format is i'm still going to do this one task because if you get to where you're trying and this one if you go to my it's actually one of my most popular videos um it is i i had already figured this out so let me show you um let's see view count this one so fine tuning to generate questions about anything i actually this is where i had figured that out is because i found that if um when i was doing when i was originally doing this experiment if i wanted it to ask questions about dialogue like it would say like ask as a third party observer to ask about what's going on here it would actually try and participate in the dialogue and i'm like no no no i'm not asking you to jump in and be a participant in the dialogue i'm saying ask questions about what's going on here and then i would switch and say like ask questions about this news article right and so by having disparate formats of data different kinds of input data with your with your when you're generating synthetic data you can get better performance because it will say oh you want me to generate questions of this particular format every time irrespective not irregardless it's not a real word irrespective or regardless of how the how the input is formatted um so that's a really critical thing and i realize that i haven't ever really fully explained that um and so you know professor hat um okay so that was the first thing and um and this guy and i i do have to apologize because like i was i'm not in that mindset of like oh i'm i'm here as an educator so this is me practicing being an educator um and so then he said like oh well when you say confabulating and hallucinating that sounds like it's too far from the truth which is technically yes but hallucination and confabulation in transformers or large language models is different so this is one of my favorite diagrams of all time um it's a it's the difference between accuracy and precision right so if you're precise you have a very tight cluster a very tight group and so you see on the right side where you have high precision it's like very precise so you you say okay this is the answer but in this case it's far from the truth and then if you have something that is both accurate and precise it is consistent and close to the bullseye and on the other hand if you have something that is neither accurate nor precise it's completely random right the output is completely random however with so this applies to normal machine learning models like um support vector machines k nearest neighbor those sorts of things any kind of regression this applies with large language models this this does still apply somewhat but confabulation is an entirely new phenomenon and so the um the the i found an article that talks about like what confabulation is um and so confabulation is something that happens in people where you just make stuff up it's completely fabricated you're filling in blanks and the key word there is that it's fabricated um it has nothing to do with the act what what the actual input was and so what can happen with gpt3 especially the older models like the original davinci and curie is it goes off the rails this that's just the turn of phrase that a lot of people end up using um is that it's completely making up its own narrative it's not attached to what you what it the input was at all the more recent instruct series the text davinci o2 ones those have had a lot of that fine tuned out of it but it will still do that it'll still just completely start making up its own thing and so what i did was i created a graphic to help explain that and so i said like imagine this field is a little bit bigger right and then you actually have this thing where you have like negative precision or negative accuracy it's not even zero precision or zero accuracy you actually end up with negative values when you have hallucination and confabulation because it's giving you stuff that it shouldn't even have access to it it's giving you information that was in no way remotely contained in the original input so confabulation and hallucination are entirely new machine learning concepts um and this i realize is also not intuitive especially if someone is coming from a a purely math background um so you know that this this is a really important thing to talk about which is one of the reasons i was inspired to make this video and then there was something else i don't remember i think that was about it um yeah so you know accuracy precision but then confabulation whole new whole new animal um i think that's about it yeah so uh gr good questions and again i just want to reiterate like i'm stepping into a new role as an educator i'm not just sharing you know because most of what i've done up to this point is being like working entirely on my own um just kind of like off you know writing books doing research which that's one thing right as an individual contributor but as someone that like now people like a lot of you are asking questions and sometimes like we're on different wavelengths right like i have been keeping up with synthetic data right the idea that you can use transformers to do synthetic data but not everyone is up to the same speed right and that is me learning about my role my new role as not just someone who's doing research and sharing ideas but also as an educator so if i have again i'll just reiterate if i have not been as helpful as you would like i'm learning right i'm i'm learning to teach and i'm learning to do this better all right i'm repeating myself now so i'll go ahead and cut it off but there you have it um the short answer yes synthetic data is perfectly legit um there are certain strengths and weaknesses as with all methodologies in science so thanks for watching and uh check in check in again later