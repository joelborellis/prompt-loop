morning everybody david shapiro here um today we are going to go over maragi so moragi is kind of my magnum opus that's my big project other than the heuristic imperatives it's an open source project and so the purpose of this presentation is to orient you to the entire project so we're going to talk about the architecture of maragi and also the road map so first of all what is maragi meragi in a nutshell it's an acronym that means microservices architecture for robotics and artificial general intelligence i originally came up with the concept of maragi in late 2017 or 2018. it is a type of cognitive architecture so basically a cognitive architecture is a way to build a thinking machine or a reasoning machine cognitive architectures have been around for about 50 years they are used in things like deep sea deep sea remote operated vehicles or autonomous vehicles the mars rovers use cognitive architectures tesla cars use cognitive architectures so that's not anything new this is just a different type of cognitive architecture so maragi uses cognitive modules to approximate the neural functions of the human brain so it's not a structural copy of the human brain it is a functional copy of the human brain it uses natural language to think so all thought in moragi is written in natural language which means that it is interpretable and transparent but most importantly and you see this here it is an architecture to achieve functionally sentient autonomous machines so that's the two two primary things is that there will be functionally sentient and autonomous autonomous um they'll also be learning machines that's implicit um so now for the architectural overview at the highest level the architecture of maragi is a hub and spoke or a startup star topology this is because this is the easiest conceptually the nexus is at the hub so the nexus is a microservice that we'll go over in detail in just a few minutes um but from the simplest way to think about the nexus is that it is um functionally a syslog server it's it's for storing and retrieving logs now these logs are the thoughts or the memories or the sensations everything that that the artificial cognitive entity acquires or sees or hears or learns or thinks is going to be stored in the nexus so you can think of it as the central database the central repository a log server those kinds of things from a functional standpoint in terms of artificial cognition um it's the stream of consciousness um and so what i mean by that is that everything that the machine needs to be conscious of needs to end up in the nexus so each record in the nexus we see here is time stamped with a uuid and then it also has to contain some kind of content or metadata and we'll get i'll give you an example of those in just a second all the other microservices all talk to the nexus hence the name nexus it's the center of everything they talk via an api or some other interface there's other options we'll talk about that also in just a second but the key the key takeaway here is that it is a star topology because that is the simplest about the nexus it's the stream of consciousness for artificial cognition so it's a data repository for the acog or artificial cognitive entity it holds all memories sensation thoughts and ideas and plans it is indexed and searchable so this is critical the nexus serves as the memory center it's the consciousness and memory center of maragi which means that it has to be indexed and searchable that means you can use any kind of of a search engine right you can use solar elastic search you can use sql light if you want to um there's there's other possibilities um everything in it has to be a natural language though um there's not going to be any like code or abstract representations the exception is going to be vectors semantic vectors for search purposes but even still that's not even required if you have if you have an embedding or a vector for search that's only if you're going to use semantic search but you can use other kinds of search methods such as more conventional indexing by using existing technologies like solar elasticsearch elk stack there's also vector-based search like milvis weaviate and pinecone that will allow us to scale to many gigabytes or even terabytes worth of data for our artificial cognitive entities so that problem is already solved um so basically for the nexus we're gonna probably use something that already exists rather than making our own custom solution uh the stream of consciousness so kind of as i said everything that the the uh that maragi or the the artificial cognitive entity needs to be aware of must end up in the nexus um it's the heart of everything hence the name other services add messages to the nexus and then they also provide search so there's a two-way communication there so what would a record in the nexus look like so first there's going to be a time stamp this is true of all syslog servers is that it's a timestamp because you got to know when you received that message then i also recommend having a uuid which is a universally unique identifier which means that every single thought um or sensation or action that the the the meragi takes will have a uuid a unique identifier so that you can reference that specific action decision observation whatever it should have some kind of content which is a natural language entry and there's some examples on the right hand side that we'll go over in a second you might also have the originating service or model that produced that message that's going to be necessary later on specifically for learning so that that way you can label all of the data and have an ml ops a machine learning operations or machine learning pipeline so that everything can learn as it goes um heuristics and and and learning are critical to this design um and then you can have some context such as like metadata or a natural language purpose no for an example we have a timestamp of 123.456 the heuristic imperative service reduced suffering to reduce suffering in this situation we should rescue the dog from the river so just this example which i just wrote by hand gives you a little bit of idea as to like what one single thought is going to look like here's another one 456.789 camera service visual input i see two men playing chess in a large park that looks like central park in new york city again this gives you just one sentence um you know one or two sentences per log gives you enough information to kind of understand what's going on um 987.654 executive action action decision i'm going to walk to the store to buy milk again very simple um and and what's going to ultimately happen is that the nexus is going to hold tens of thousands millions billions of records like this all in chronological order from different services it's all going to be compiled together into a single source all right so recap of this first section maragi is a star topology or also called hub and spoke centered around the nexus the nexus is functionally a syslog server or database there's all kinds of ways to implement that as long as it is searchable that is the key thing as long as it is searchable and it allows for some fields principles of microservice so i mentioned microservices it's a microservices architecture so what is a microservice and why do we use them at the highest level a microservice is a way to break a large complex piece of software into smaller more manageable components so rather than build one monolithic piece of software we're going to build it in as a service oriented architecture or a microservices architecture so microservices are good for parallel processing meaning that you can have different pieces all running in parallel with no dependencies on each other which means that they can keep running even if one fails you can replace it which is really good for resiliency so for instance let's say you've got you know your your machine running and then one service drops off you can have a supervisor that restarts that service or fixes it or says hey pause we're missing a service without the whole thing crashing um another big advantage of a microservices architecture is it allows for the system to grow over time without re-architecting the whole thing and that's why we have the star topology is because you just add new microservices and they all talk to the nexus via a standard interface which allows you to grow meragi over time without having to change anything meaning if you come up with a new micro service that you need to add you just add that in or if you need to swap one out you say hey we're going from version one to version two of a given microservice you just swap it out without it nothing else breaks which is another reason that you have to have standard data formats such as timestamp uuid content so it doesn't matter where it comes from as long as the log follows the correct format then everything will be fine as long as you have that standard format okay microservices form a network so this is talking kind of more generally about microservices they can be in any number of topologies such as a mesh star ring or bus um so this this graphic here is how a mesh topology might work where everything is kind of interconnected as a web i chose the star topology because it is by far the simplest layout um i did try other topologies um earlier in this in this project back in 2018 and 2019 and trust me hub and spoke is the easiest trying to create feed forward networks or mesh networks with this is really really complex um let's see there are different kinds of ways for them to interact so you can do rest you can do amqp you can do graphql you can do all kinds of things there's also the possibility that we can just use orchestration engines which kind of have their own internal apis but we'll get to that we'll figure out the correct way or the best way to implement it later on personally i prefer microservices because they can be written in any language and they and and they're very small and they don't they don't rely upon like a big uh platform and you don't have to worry about getting locked into any particular orchestration engine so i would prefer to stick with microservices but there are orchestration engines out there that could also be used to implement meraki all right so there's a few basic rules that i've already figured out and established for microservices for meragi specifically so the number one rule is microservices only talk to the nexus they don't talk to each other directly the nexus is the common broker for all messages so anything that they need to say goes into the nexus and then ever because the nexus is the single source of truth for all thoughts all microservices also pull from the nexus another the second rule is that they have to listen for the conductor we'll go over the conductor in just a minute but the conductor provides feedback and cognitive control to all the other microservices to steer everything um the mic number rule number three is the microservices must be auto didactic meaning they learn on their own sorry i've got something in my eye um they learn on their own um by observing their own behavior and observing the feedback that they get from the from the conductor so we'll go over how to create auto didactic services in the future basically it's a machine learning pipelining problem which is nothing new it's just a matter of integrating large language models into those machine learning pipelines they should use a combination of prompt prompt chaining and fine tuning eventually we'll probably just do all fine tuning although i can't say for certain each micro service runs as an infinite loop so basically it will periodically check the nexus for messages do its own work and then maybe add a message and then it'll go back to sleep and then wait again but it can change its tempo it can change its cycle rate based on feedback from the conductor and then finally this goes back to being autodidactic each microservice will use data from the nexus for training and refinement over time so as it gains experiences and it gets feedback from other models then it will learn to do its own job better so basically think of it as a generative adversarial network with multiple services all contributing all right so what microservices are planned or needed so here on the right i have just a real basic diagram of the first handful of microservices where we've got the nexus which remember is basically a syslog server some kind of output a simulation service so rather than having input from the real world where i'm starting is having it in simulation because that's safer and easier anyways the heuristic imperatives conductor discernment prediction okay so again uh hub uh star topology hub and spoke so the nexus we already talked about the nexus that's the center of everything the oops sorry come back um the conductor is what does cognitive control and we'll go over that in just a minute the heuristic imperatives is also critical we'll go over that in just a second then other microservices would be input or sensors like cameras and microphones whatever they whatever input comes into meragi it must be a natural language again everything is going to be a natural language so if you have a piece of hardware it whatever whatever that whatever that piece of hardware picks up it must then be translated into natural language before it's put into the nexus then you might have planning services so planning services are going to be like okay based on this goal how do i get there what are the steps that i need to do discernment so that's like risk and costs a cost assessment so discernment is a discriminative type of service where it says okay i shouldn't do that because it's too dangerous or i shouldn't do that because it's going to take too long that kind of thing prediction and forecasting so prediction or forecasting is about saying okay based on the way things are going now and these ideas this is how i think it's going to turn out and that's all it does it just predicts the future and adds that information back into the nexus so that other services can make use of those predictions um then we also need an llm and or embeddings of some sort and so these it's kind of floating off because all the other this is the only service that other microservices use but this could be like a cloud-based service it could also be a local model that's running on hardware it doesn't necessarily have to be a microservice as other things but it is important to say that we do need large language models and embeddings for this to work another service or set of services that we need is error detection and or fact checking so error detection is really critical because at all times part of our brain is always monitoring our own behavior to make sure that we are behaving correctly um and that we're not making mistakes so for instance if you say something wrong you might say oh wait i didn't say that right and then you get a unique signal in your brain saying hey you messed up um and so there's different kinds but we also monitor other people's behavior right we monitor reality around us to make sure that that what other people are saying are doing also makes sense so that's what error detection and fact checking does and then we also need some kind of executive or output microservice so for instance one executive service might be a decision to speak right so you might have a test a text to speech module that says okay given all these decisions that i made let me generate a dialog option and say it that sort of thing so these are just kind of a handful of the first microservices that are planned i've got a few of these started they're up on my github which you can just search dave shap and you'll see the some of my services up there so quick recap for the architecture section microservices only communicate with the nexus that is critical that is the definition of a star topology microservices are auto didactic meaning they focus on one task and they learn to do it better over time that's the key takeaways thought first model so what do i mean by that when you can think about anything how do you choose what to think about large language models around allow for arbitrary nlp which is natural language processing natural language generation and natural language understanding meaning they can do anything as long as it's a language based task they can do anything so they can think about anything so say for instance you fire up a large language model you can ask it to pretend to be a cartoon character you can ask it to wax philosophical um it's in they're incredibly flexible they're the first major step towards general intelligence towards artificial general intelligence but with great flexibility comes great risk because they can just as easily be benevolent as they can be evil so how do we steer these powerful machines this is the first problem that we have to solve and that's why i call it a thought first model of intelligence so the primary microservice for steering um uh the the moral behavior the ethical behavior of meragi is the heuristic imperative service so um over the last few years i've developed what i call the core objective functions or the heuristic imperatives which are listed here number one is reduced suffering for all organisms number two is increased prosperity for all organisms and number three is increase understanding for all intelligent entities so what do i mean by a heuristic imperative so a heuristic is that the machine must learn about these over time and develop its own understanding and intuition so whenever you look at any moral framework or whether you look at it through a philosophical lens or a biological lens or a psychological lens all morality and all ethics must be learned there's no um that's that's one of the universal things that everyone seems to agree on is that whether it's whether you're doing like virtue based ethics or deontological ethics which is duty-based ethics or teleological ethics which is outcome or consequence-based ethics learning is critical right because if you have deontological ethics or virtue-based ethics you must learn what those virtues are and you must explore those or explore what those duties are right and then there's always room for debate or change over time then if you look at ethics and morality through for instance a biological lens or evolutionary lens or psychology lens children are not com like children are born with only a few basic instincts for morality such as like fairness which is mediated through things like anger and attachment um and so as as humans we learn morality by interacting with other people and by interacting with the world and so that's why um the best solution for agi alignment is to build learning into the morality which also means that it's going to be flexible right you don't have to define everything up front but you do have to define learning as a critical step in developing a moral framework so that's what i mean by heuristic they are heuristic imperatives um and that's also built in with um imperative number three which is increase understanding for all intelligent entities which includes itself so it has its own imperative its own moral and objective imperative to learn and so what is an imperative an imperative is an intrinsic drive or something that it must do right it's something that animates this machine that if it's just sitting there on its own doing absolutely nothing else it's going to be thinking about these three goals so because those are what it's doing at all times its impulses will be in alignment with these objectives so in other words it's all about learning and goals that's what a here is to comparative is it's about learning and learning to achieve those goals the machine will gain knowledge and experience over time another important thing is it will try to satisfy all three objectives every time which creates dynamic internal tension between those three different objectives because sometimes they'll be aligned but sometimes they're going to be in tension with each other so for instance you know if you just have reduced suffering for all organisms you might end up just exterminating all life because you can't suffer if you're not alive right but that's going to be in dynamic tension with increased prosperity for all organisms why because prosperity means to live well so you want to reduce suffering while also encouraging a good life right and prosperity looks different for everything um every individual person and every different organism prosperity looks different and so but when you say like okay so there's going to be some dynamic tension between these objective functions but there's also going to be complications because it specifies for all organisms right how do you reduce suffering for all organisms you have to make compromises and so that's what i mean by dynamic tension is that it's going to be impossible to fully satisfy these at all times which in my experiments gpt3 and other large language models are very good at actually looking at the nuance of these of that dynamic tension and so by having this dynamic tension and embedding it into the architecture it will guide and self-correct forever and i know that's a huge promise and we've got to test that um but all the experiments that i've run so far it's been pretty robust okay so that's heuristic imperatives that's one of the key microservices the conductor the conductor is the orchestrator of this symphony of thought so the conductor is another microservice this is the like next most critical microservice so what does it do the conductor is responsible for cognitive control so what is cognitive control cognitive control is the simplest thing is it's your sense of discipline it's saying i'm doing this because it's the right thing to do or it's because it's what i should be doing but then how do you decide what you should be doing this is where the heuristic imperatives these say this is what our goals are this is what we should be doing and then the conductor says okay based on based on that should that ought let's set priorities and measure performance in terms of our adherence to those goals so it's about it's about setting priorities and measuring performance so another way of looking at that is that it's about task selection it's saying okay which task should i work on and if the priorities change how do i switch tasks so those are that's what that's what it means to have cognitive control is setting priorities measuring performance for those priorities choosing tasks and switching tasks so the key question that the conductor asks is am i performing well and then it provides feedback on how to perform better another way of looking at it from a from a freudian perspective is that the conductor is kind of like the super ego for the machine it says here's my ideal self how do i get to that and by virtue of being the conductor it tugs on the little strings for all the other microservices it keeps them in check and provides feedback to say hey you need to do better and we'll get into more details about what those kind of buttons and levers are in the future so quick recap the primary micro services are the nexus which is basically a syslog server the heuristic comparative service which is the moral compass and then the conductor which is the cognitive and control module there are many more microservices that are needed but they can be added over time because we're using the star topology all right roadmap so we've gone over the architecture and the overviews so let's talk about the roadmap where are we and where are we going so where right now the current goal is to implement moragi version 1 which means the first thing that i need to do and i've already had a few folks jump in offering to help first thing is we got to finish the microservices so i've only got a handful of the microservices we're not quite halfway done but a lot of the first principles have been figured out so it's only a matter of time to do the prompt engineering and so on to get those micro services working i'm sure we're going to uh trip over some bugs and you know unforeseen consequences um another thing is we got to test different implementations right so there's different types of apis to use there's different ways to implement the nexus there's different ways to do search so we're going to be working on getting kind of establishing those baseline like best practices making some architectural decisions doing some prompt engineering this is just getting the thing to work it's going to be messy but we got to get it to work the first time so moragi v1 goals to so to put it in terms of an agile roadmap first we have to test various technologies and platforms so we're going to test rest apis graphql elk stack airflow whatever else there's all kinds of ideas flying around out there and like i said at the beginning of the presentation there's more than one way to skin this cat but the principles are there and so we're going to work on demonstrating a proof of concept for all microservices so that's one of the key goals of mirage ev1 is get a proof of concept working it doesn't have to be good it doesn't have to be solid it just has to demonstrate the concepts of artificial cognition and in particular those feedback loops it's about nested loops it's about loops within loops within loops and so on so once we get all the best practices and principles established then i'm going to put it all together codify it in a book and then publish that book for free let's see we're also going to begin work as it's going to be fully open source with a distributed team so i put out a call for participation yesterday and i've already had four people volunteer to jump in and contribute in different ways um this is it's not just up to me and i have already just after one single call i've already had new ideas and and learning by the feedback that people have have given so like you know when you have a team working together it's basically humans acting as generative adversarial networks where you got different people proposing different ideas and then together you come up with better solutions than you could come up with on your own so that is moragi v1 goals is get the book out establish a distributed team prove out artificial cognition and feedback loops implement the proof of concept for all the microservices and test the different technologies so that's v1 next steps on the road map so i typically follow a five release model um it just to me that kind of things uh that works best in terms of my training with agile so maragi v2 we're going to focus on fine fine-tuning in the conductor for version two so we should get to the point where we're using fine-tuned models for all microservices fine-tuned models are going to make it more portable because that means we can switch to like gptj or bloom or any other models because once you've got a fine-tuning data set it should be portable to any other large language model that's the goal here um step part of that uh something that flows from that is that with version two to be complete all the microservices should be autodidactic meaning that they um that they curate their own fine-tuning datasets and fine-tune their own models over time but then they also have to do a b testing to figure out which models are best so auto being having auto didactic microservices that is not a trivial task that is a very difficult task um and a part of that is the conductor we need to have the conductor fully operational with version two meaning that the microservices pay attention to the conductor to modify their behavior in real time and also use the feedback from the conductor to curate those data sets so you see how it's all tightly integrated another goal for fi for version two is to have a good simulation environment right now the simulation environment is really rudimentary um we can also start thinking about optimizing for cost and performance um some of that is just going to be waiting for newer more efficient models to come out and also bigger gpus to come out um some of these some some large language models are more efficient than others and this whole industry is being advanced all the time so some of that's just going to be a function of time but some of it is also incumbent on us to optimize our system as much as possible um so the the the last part of version two is um we we ought to be working on proving the robustness of the heuristic imperatives we'll get more we'll get more to that in in future releases though um so version three version three or release three is where we'll start working on hardware integration so we'll start integrating things like cameras microphones and speech microservices um we'll continue refining the uh refinement of the architectural paradigms best practices and implementation version 3 is going to be the first time that we're going to aim for public consumption so basically it'll be all the software will be open source we'll start to put it on like smart home devices and allowing people to test it in their own home on their own terms right so again it's going to be open source so it's going to be basically use at your own risk but we're going to try and get it into the real world so that you can interact with a moragi system in real time in a real environment to to test it and get that get that feedback because we'll we'll need that feedback um but not after doing a lot of optimization and also proving the robustness and safety of the heuristic imperatives version four scale security and stability so this is where we start to think like okay we've solved all the all the rudimentary problems let's start to expand so uh some of the questions that we might have to answer for version 4 is where do those services run um in some cases you know depending on how optimized things are it could run on you know like if you've got a decent um home computer they might also you might need to have some of these services run in the cloud we might need to figure out blockchains and other things for security and privacy so security privacy and safety are huge um and so we'll need to we'll need to think about that right so for instance if you've got a smart home device that's always watching and listening you want that data secured at all costs you would rather lose that data than have it stolen so that is going to be absolutely critical to figure out before getting too far along in the project is we we've got to figure out safety security and privacy um results where to go resiliency so again we're going to continue trying to break the heuristic imperatives we want to ensure that that this machine will never be evil and that even if it has the chance to reprogram itself that it will choose not to or that it will choose not to do experiments to break its own heuristic imperatives i've already done some experiments where where if you do it right it thinks through and says i'm not going to make that change because i might create a version of myself that does not adhere to my goals and so we'll do we'll also continue doing longitudinal tests long running simulations again by by creating simulation environments we can test these things to fail failure to see if or when the heuristic comparatives fail and under what conditions so that we can adapt the rest of the architecture or the heroes to comparative service so that it doesn't fail ideally um moragi version five so this is the final release this is going to be deployment for mass consumption so basically you know release it models that are going to be for like smartphones smart home etc so consumer consumer deployment this is i'm not i'm not planning on doing this for profit mostly what i want to do is is get an open source version out there under the mit license so that for-profit companies can deploy it if they want um so there's gonna be the consumer level um there's gonna be an aim for business level such as having executive assistants that can you know that you know a manager can talk to like hey how do i do this um and that and that maybe you can have a version of meragi that connects into like your company database so that you can have this smart agent that can you know either help you out as as an assistant or could even possibly do some work and then there's also the government level so for instance one possible way that that maragi that this system could help is that it could be an interface between citizens and the government so that like you can ask questions like how does the law work or what how do i do my taxes or you know to basically be a go between an intelligent agent that can be um that can they can be basically a civil servant is kind of the goal there of course there's any number of implementations that i can't even think of once you have a general purpose intelligent autonomous agent but really the goal for version five is to get moragi systems everywhere in the world to provide intelligent agencies um stability and positive influence because remember the goal here is to create autonomous machines that are going to behave benevolently for all time so that is the road map so going back version one is test proof of concept prove out the things get some best practices and start as a distributed team version two get the fine tuning and the conductor worked working um version three hardware integration version four scale security stability and i probably should have added safety but that's kind of implied and then finally version five is mass deployment and integration so recap we're just getting started there's a long road ahead but there is no there are no barriers anymore all of the necessary technologies are out now it's just a matter of doing the research doing the implementation and testing it the bit the last barrier was the large language models and those prices are coming down fast and there's lots of open source ones coming out like the um amazon just released their alexa tm there's bloom um there's all kinds of other models that are coming out and they're coming out faster and faster as this research is accelerating so there is no longer any barrier to for success here it's just a matter of doing the work so thank you for watching um please consider joining the team um reach out to me um there's also the discord link in my youtube video in the description um and also consider supporting us on patreon um every little bit helps because uh eventually maybe one day i'll be able to do this full time but right now i still have my day job so with that being said thanks for watching um and let me know if you have any questions jump in the comments or jump in a discord server talk to everyone later