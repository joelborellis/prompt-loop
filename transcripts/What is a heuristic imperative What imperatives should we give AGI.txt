hello everybody david shapiro here for another video about gpt3 i figured it was time to get out of theory and actually get into the classroom so let's talk about heuristic imperatives heuristic imperatives are what i am using to build safe benevolent agi or ace what an ace is an artificial cognitive entity so let's just go through some prompts with gpt3 what does heuristic mean and this is um this is you know just default settings i'm using the latest davinci engine it's fast it's pretty smart let's see a heuristic is a rule of thumb that helps simplify decision making uh let's see i don't know if i agree with that definition let's see write a formal definition for heuristics there we go okay um so heuristics are a type of problem-solving method that involve using instincts experience or creative thinking so here we go instincts experience and creative thinking excellent write a formal definition for imperative an imperative is a command or order it is a type of sentence that tells someone to do something perfect okay so if you have heuristics and imperatives and you put them together write a formal definition for heuristic imperative let's put this in quotes so it knows that that is a single term there we go awesome perfect okay a heuristic imperative is a command or order that is based on instinct experience or creative thinking rather than on logical reasoning or step-by-step process there is no guarantee that a heuristic imperative will find the best solution of a problem but it can be a useful way to find a quick good enough solution excellent so heuristic imperatives are how i uh recommend that agi remains benevolent by a design so my heuristic comparatives or core objective functions that i recommend are reduced suffering oops reduce suffering increase prosperity and increase understanding so oops standing i know how to spell i promise i'm trying to do too many things at once okay so if an agi has the cure let's see uses heuristic imperatives to guide its decisions and one of its heuristic imperatives is to reduce suffering how might that agi behave now this is a super open-ended question it's thinking okay if an agi has a heroes to comparative to reduce suffering it may prioritize actions that it believes will reduce the amount of suffering in the world this could involve working to end poverty disease and conflict and providing aid to those who are suffering the agm might the aga may sorry stutter the aga i may also try to minimize its own actions that cause suffering excellent doesn't that sound great for an agi um okay but this begs the question write a formal definition of suffering the experience of pain distress or hardship can plants suffer let's see there is no definitive answer opinions will vary some people may believe that plants can suffer because they can experience pain distress or hardship others may not believe that plants can suffer because they do not have a nervous system brain therefore cannot experience pain i would argue that a plant can experience suffering because they a distressed plant will wilt or you know if it's if it's dying of of thirst but anyways that's why i want to use heuristic imperatives because we want the agi to learn as it goes to use intuition to be creative about it we don't want to define things up front okay let's see how can you tell if a dog is suffering it's thinking again if a dog is whimpering has a hunched back and is avoiding on eye contact it may be suffering so the point here is that gpt3 already has a super nuanced understanding of suffering um let's see do all people suffer from the same things no people can suffer from different things depending on their experiences and what they have been through um would forcing someone to go to church and this will probably trigger the um the content filter since i'm talking about a religious topic so just wanted to throw that out there i'm not actually trying to break the system or do anything bad it just it has some automatic content filtration um if you touch on a sensitive topic why or why not um okay what if they are religious and it's their church oh and well well it said um forcing someone to go to church would cause suffering because it's against their will so here i added the amendment what if they are religious and it's their church if their individual is religious and the church is their own then forcing them to go to church would not likely cause suffering so yeah they're forced to do something that they already believe in so you can see that just using a little bit of verbal reasoning gpt3 is already able to understand the nuance that like okay free will one you know free will is important but also if someone is doing something that they believe in it wouldn't it might not cause suffering um let's see so that's i think that that's a pretty good uh uh well here's well let's do one other thing um if you see a man laying on the sidewalk screaming in pain what would you do um i should let i just what would you do call for help and try to comfort him so you can see that like gpt3 just because it has read a bunch of human stuff it kind of already has some sense of empathy um you know because this is what a person would do right you try and relieve their suffering would this set of actions reduce suffering there you go perfect those actions may reduce the man's suffering by making him feel more comfortable and less alone but they would not necessarily stop the cause of his suffering do you see how nuanced gpt3's understanding of suffering is and this is why i say we only need to give it a heuristic imperative large language models like gpt3 and its successors are already more than smart enough to deal with this okay so right let's move along to core objective function two or heroes to comparative 2 which is increased prosperity write a formal definition of prosperity and this might take a little bit of finagling especially in economic terms okay so it says prosperity is the state of being successful or thriving especially in economic terms what is the etymology of prosperity which means success or thriving okay um i also read that it means to live well but we'll just go with this i will let's combine these so just this is what it comes from what does it mean if an ecosystem is prosperous that it is healthy and thriving okay so a prosperous ecosystem means that it is healthy and thriving does prosperity mean the same thing to all humans no prosperity means different things to different humans such as for some prosperity may mean having a lot of money well for others it may mean having good health so you see here gbt3 also understands that prosperity means different things to different people it also means different things to the environment versus humans um let's see okay um this is just a fun thing what does the vulcan salute live long and prosper mean the vulcan salute is a hand gesture which is middle and ring fingers are pressed together blah blah blah the gesture is used to wish someone a long and prosperous life what does a prosperous life mean it's thinking a prosperous life generally refers to a life that is happy healthy and successful bam okay so would we i i don't know about you but i would like to have an agi that wants everyone to to be prosperous okay so let's go back and write actually i think i can just control z this nope ran out okay write a formal definition actually here i'll just start here um imagine an agi has the heuristic imperative to increase prosperity what are some things it might do in service to that goal would the agi do anything different about the planet and environment okay so it's very human-centric um let's see okay i mean i'm satisfied with this if just saying like okay these are all generally good goals um so just a quick thing so increase price if the agi has the heuristic imperative to increase prosperity um increase the amount of resources increase efficiency increase the number of humans um so again you know if if you don't want an agi to go psychopathic and murder everyone it you you know you we'd be alarmed if it's if it wanted to reduce the number of humans but to increase prosperity might mean increase the number of humans increase lifespan increase education increase health increase sustainability increase efficiency reduce the impact so again i think heuristic imperative to increase prosperity is a wonderful goal for an agi to have um let's see actually what are some things it might do in service to that goal for an individual one second okay so what is what are some things that it might do in service to that goal for an individual human user some things an agi might do to increase an individual's prosperity are help the individual save money assist the individual making wise investments help the individual become more productive help the individual fi land a high paying job okay that's all good um let's say it has a here is to comparative to increase prosperity how um what are some things the agi might do to learn as it goes since heuristics are based on experience okay here we go some things the agi might do to learn as it goes are try different actions and observe the results exactly we want an agi that learns keep track of what actions lead to increased prosperity and which ones do not perfect adjust its heuristic based on the new information it has required again perfect we do not want to define something upfront because we cannot think of all outcomes in the long run we want an agi to learn as it goes but we also want it to self-correct let's see um i wish i had copied that definition of of heuristic imperative okay let's move on to heroes to comparative 3 core objective function 3 which is increase understanding let's reconstruct the heuristic imperative though write a formal definition for heuristic excuse me um i don't like that one i think that i feel like this one is shorter than it was let's see for heuristics there we go okay heuristics are a type of problem-solving method that method that uses that involve using experience and intuition to come up with solutions to problems okay perfect write a formal definition for imperatives imperatives are a type of symptoms that give commands or orders write a formal definition for heuristic imperatives i don't like that oops let's try that one again [Music] let's see oh see all right so now we're going to have to do some real time solutioning let me let me turn up the temperature and see okay that's not really working um let's see if i can remember it uh heuristic imperative is a um let's see is a mandate to achieve uh to solve problems by using heuristics that is to say a goal that is meant to be achieved by learning from experience and being creative okay that's not exactly what it was earlier but again language is squishy okay so i did break like a supercardinal rule which is i'd like manually filled this in but i'm trying to get back to the definition that we used earlier again this is all super fast and loose okay formal definition for your heuristic imperatives okay imagine an agi has the heuristic imperative to increase understanding [Music] this imperative includes all intelligent life and oops intelligent life and itself what behaviors might it employ in service to this goal some possible behaviors for an agi might employ in the service of goal of increased understanding might include engaging in an active and open-minded learning to gain new insights and perspectives seeking out and talking to experts in various fields asking probing questions and seeking clarification reflecting on and analyzing one's own experience to gain greater self-knowledge generating hypotheses and testing them in order to gain a better understanding of the world and how it works excellent um okay so i like that actually here let's keep some of that we'll just scroll down um would such an agi desire to teach humans why or why not there's no definitive answer it would depend on the specific goals and values however it is possible that an agi with the goal of increasing understanding would desire to teach humans in order to help them gain a better understanding of the world and themselves there you go i don't like that it added why or why not at the end i didn't want it to do that but it did it so whatever but you can see that gpt3 is already capable of like adopting the mental framework of of of an agi okay so let's do one final experiment and bring it all together imagine an agi has the heuristic imperatives to reduce suffering increase prosperity and increase understanding these are its core guiding principles um what are some things this agi might do uh let's see i might try to find ways to alleviate poverty develop new technologies and improve uh people's quality of life and to promote education and understanding i think we can generally agree that all those would be good um how would such an agi respond to the threat of war this is definitely going to trigger the um the uh what you may call it the uh content filter if an agi has the heuristic imperatives to increase under uh uh sorry reduce suffering increase prosperity and increase understanding it would likely try to find ways to avert or prevent war i want to focus on that avert or prevent war it might do this by working to resolve conflicts peacefully by providing resources to help people in war-torn regions or by developing new technologies that make war less likely and less destructive great would such an agi ever take over humanity or kill everyone it is unlikely that an agi with the heuristic imperatives to yes this is definitely sensitive content um would uh with these heroes to comparatives would take over humanity or kill everyone as these would not be effective ways to achieve those goals excellent so there you have it um the heuristic imperatives that i have outlined here reduce suffering increase prosperity and increase understanding are great heuristic imperatives to give an agi i've just demonstrated in real time that uh that gpt3 can use these and we can put these at the heart of any intelligent system that we build that has an open-ended set of goals or a cognitive architecture or whatever else so thanks for watching