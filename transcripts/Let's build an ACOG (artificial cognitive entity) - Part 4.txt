morning everybody david shapiro here back with a video about acog artificial cognition i was uh i started working on this while letting my coffee brew and i realized like wait i should be recording this um so let me just bring you up to speed with what i've done so far i haven't done much um but i jumped back in um i cleaned up the prompt list and i renamed it because um this initial set of prompts i was like i thought i was working on the cognitive control prompt but there's a step before that um so i let my brain kind of do its thing for probably about a month i think it's been almost exactly a month since i worked on this so that was enough time to let everything kind of digest in the background and so i had an initial prompt list and the first before you can do cognitive control you need to know what's going on right you need to know um what what has been going on um up to this moment you need to know uh what's important right now uh you know like are there any dangers are there any threats is there anything that's good that's gonna grab my attention um and so you got to kind of get everything up to speed because like imagine you like wake up right what's the first thing you do if you like wake up in the middle of a war zone you get oriented right so you need an orienting loop in order to um understand what's going on so in so what i did was this initial um list of prompts i say like okay what are my core objective functions and i'm gonna start calling these as a heuristic imperatives because calling it an objective function is throwing off a lot of people i'm finding an objective function makes it sound like more of a math term whereas a heuristic imperative is uh much more precise in terms of what it actually is so we've got the heuristic imperatives which is reduce suffering increase prosperity and increase understanding and then we've got persona or what would actually be ego so basically as our cognition stays awake longer it learns about who and what it is so it forms an identity over time um and then we ask okay what were we working on what is our task and these are all prompts that exist right so they're all not all of them are here but many of them are here um so i've got these prompts started and eventually these should all be fine-tuned right because um you get a lot of variability um write a detailed list of potential actions yeah um okay so um and actually a lot of these are going to get changed out um so but let's see so tasks so what are we working on um so a huge part of goal tracking is saying this is what i'm working on this is my goal um and because part of uh like people with executive dysfunction their brain will switch goals or lose goals really quickly so like if you have adhd you might be like walking across your house and then you see something else that needs to get done and this is how i know that i at least have a little bit of adhd is because like i might be like cooking right and then i need to go get something for my room and then i'll see that there's a laundry basket i'm like oh i got to do the laundry right and so you see something and you change goals that is that is a lack of cognitive control so in order to to make to stay on task you actually need to ask yourself okay going back over my recent memories what is it that i'm working on and what should i be working on and but the ability to switch tasks is really important because imagine so that you know it might be like oh well adhd is so bad right it's like actually i saw an article recently that concluded that or was it a book i was reading i don't remember um it might have been a video i was watching i can't remember where i get information sometimes but the salient point was that adhd was actually probably a really powerful survival mechanism when we lived in forests and jungles and savannahs because it's like da da da da you know you're you're going and you're fetching water from the river and then you see like a lion and you're like oh got it you you change tasks immediately right and so by being aware of your environment and switching tasks based on what you see by being hyper responsive to your sensory input that's not a bad thing right you see an you see a crocodile in the river where you're about to get water you stop getting water and you pay attention to the crocodile you run back to the village screaming your head off right or so anyways point being adhd is probably not originally a uh uh a problem and the ability to stay on task is not always a good thing right because you think about someone um who who gets stuck on one thing and like will keep focusing like what is this like a a joke in a movie right where you've got like the person who's who's so heads down and focused on like filling out his forms that he doesn't you know there's a war going on and he's like but i need to do this task so being overly focused is bad and being underly focused is bad so a huge part of cognitive control is is not just staying on task with task switching so that's what this prompt will do another one is empathy so humans have mirror neurons and canonical neurons and all sorts of other systems in our brain that allow us to automatically track the emotional state of people around us um and we want our our acog to do that as well because like if we're if we're getting angry at it like you're not listening to me we want it to be aware of that um or if we're sad and it it needs to know that we're sad so that it can be like what's wrong you know um the the stereotypical robot is one that like doesn't ask you like you know like oh well i'm just gonna be pure logic right you don't want that um metacognition this one may or may not make it in um or this might be um an uh a metal loop so basically what metacognition is is it's thinking about thought so each of these individual thoughts is going to be like um you know all automatic um but this one metacognition that might be an like an observer so if you if you if you've ever done meditation the whole point of well certain types of meditation the whole point of meditation is to detach from your your conscious thoughts and just watch them okay well who's watching the watcher right if our brains have this ability to detach from our thoughts and just watch them then that means we have another perspective inside our own heads that can watch our thoughts that's the point of this so that so that our acog so that raven can become aware of the thoughts and then once you're aware of the thoughts you can also then modify them so this is this is a key step of saying like okay what should i be thinking about right because you can say what should i be doing and that's external but with metacognition you can say what am i thinking about and what should i be thinking about so this this might make it into another layer so i'll comment that one out for now prediction so another thing that our brains automatically do is we try and anticipate what's going to happen next we do that all the time it's completely unconscious and automatic and so we want our acog to be always making predictions because it's like oh this is what i see i'm just going to consciously put this into my nexus where i'm going to this is what i anticipate is going to happen next that can also be good because you can use that as training data in the future because like say for instance um our acog makes a prediction and it comes true that's good that's that's a good sample that's where we performed well if we make a prediction and we're wrong that is an opportunity for error correction um consequences so this is like the opposite of prediction this is looking backwards and this is saying what have been the results right i predicted this five minutes ago did that happen yes or no or did i do good or bad and in a previous test i showed that um if you just give gpt3 a list of log files and ask like hey did did i fulfill my goal here yes or no gpt3 is really good at saying like yes you'd reduce suffering or no you didn't um so that's good the philosophical ruminations this will probably get taken into um into the metacognition loop i'll probably just start calling that because a philosophical rumination is kind of like um you know okay well what are the what are the long-term implications here or what you know what what does it mean like you know if if raven if my acog is thinking like oh i'm a machine right that doesn't necessarily figure into um cognitive control or or decision making but it's important to have right and actually you know the persona this probably actually belongs in the metacognition loop as well something that's happening kind of in the background important questions so spontaneous curiosity this is something that absolutely needs to be in the inner loop and then important information this is going to just be automatically recruiting information from the internet from wikipedia that sort of thing i'm about to make another video about um integrating external sources of information and long-term memory into chat okay so now that you're up to speed because i know it's been a month this is also me reminding myself what we're doing so i think this is probably a good enough start for for the first part of the inner loops okay so going down here we've got our prompt list that's what we were just looking at so these are the prompts that happen every time these are the kinds of thoughts that are happening all the time the entire time that um our artificial cognitive entity is running and so what we do then is we save them out to the nexus so the nexus is going to be here i've just got the genesis um uh memory here which is just this is what i am excuse me sorry a little flammy in the morning um okay let's close these prompts we'll get to writing those later um okay so every time every time we fire up and we we lose we we run these prompts we'll accumulate the most immediate ones in a list and so that's just like okay this list of thoughts is exactly where i am exactly what i'm doing and exactly what i should be doing and i actually realize this is not the right thing so we'll have a cognitive control loop and that's what we're going to be brainstorming now so the control prompts are going to be like um so the first thing you do is okay you've got your task you've got your consequences you've got your predictions so all of these are going to end up as like one chunk right one context um and so we'll say okay so what should i be doing right or or i guess brainstorm the next steps so i think prompt brainstorm because it's like you know oh actually no um yeah okay prompt brainstorm.txt so the what the brainstorm is going to do is it's going to be um so when whenever you're whenever you're trying to do a goal so this this actually came from a discussion on my discord server um we've got a couple people that are really interested in cognitive control and goal tracking and so from those conversations one thing that i realized is that um a key part of of goal tracking and and cognitive control is you actually have to envision what your goal looks like so that's what we're gonna do um so we'll say like um [Music] brainstorming my goals so we'll call it that and then we'll just do um brainstorm okay okay so this is going to be envision what the goal looks like and maybe actually let's call this envision because that's that's going to be i'm going to be happier with that because brainstorming is actually more for procedures um so we'll say envision my goal state um so the the opening example in the book um on task by david bader he's talking about um evidence of paleolithic of a paleolithic human that was napping um flintstones and basically dividing it into multiple piles like these are good arrowheads this is a good axe or this is good for something else and and he talks about how that's actually a non-trivial um set of tasks because not only are you doing something with your hands you're keeping track of multiple uses for those stones and yeah that seems really simple to us but that's because our brains are really good at it okay so once you've given given all the information up here your current context so actually let's call these um oops let's call these our context prompts replace all and then we'll have the control prompts um so once you've got your context established and then you envision what your goal is the next step is you brainstorm so let's do prompt brainstorm not text and also i know that there's a lot and a lot of these prompts are not written so probably what i'll do is um is i'll write all the prompts offline um because i don't think you guys want to well actually no you guys you guys tell me that you want you want to see prompt engineering so we'll do prompt engineering um okay so uh let's see potential steps to um uh let's just say potential goal steps that should be enough um brainstorm okay so brainstorm actions um so this is flexible um and and i'll show you what what i mean by this is flexible in the problem because this is this is a generalized set of instructions um that gpt3 is flexible enough to implement whether or not it's a cognitive task like if you say like i need to think about the future like that's something that it can do here or if it's a physical action like you know i need to grab a rock envisioning and brainstorming both apply um since this one is not going to have any robotic output we're just going to be talking about thinking we'll get to robotics at some point in the future okay so prompt so the first thing we is we have to envision what we want to do so we've got our context which is which is established here so we've got our context and then we've got um we've got our cognitive control which is um kind of okay let's let's design our our next actions um this was about as far as i got honestly um okay so we've got we envision it and then we brainstorm and then we execute um yeah oh you know what something just occurred to me is that once we envision we're gonna this is actually gonna be prompt chaining um because we're gonna feed one into the next okay so we we we build our vision we brainstorm the steps and then the next thing we do is we say okay given our vision and giving these given the brainstorm what is the actual next step because we can only do one thing at a time so let's start there this is just my intuition this could end up being entirely wrong um let's just say uh execution um my uh next action okay so then we'll say execution so this is um so this was what i'd call like executive function right so the final step of cognitive control is actually acting on something so in that example earlier where i said like you see a laundry basket and you start doing laundry this would be like you know um let's say in your context you know it says like oh well i see um you know i saw that there was a laundry basket but i'm gonna choose to ignore that because the house is on fire right like that that's that's a prime example of where like you know adhd or executive function or cognitive control really comes in because you have to keep in mind your whole context and that will help you decide what to do now even someone with adhd like you see laundry you might think about it like if the house is on fire you might see like oh man i should do the laundry um but then you're like immediately after that you're like well the house is on fire right because you've got something in your brain prioritizing what you should be doing okay so i think this is about it um and then let's do metacognition prompts equals and then let's do persona because this one does not figure into the immediate so this is something this is another loop that's going to be going on in the background and it does not figure in directly into these other things it might not need to be split off honestly um but because my intuition says that says that it should be split off so i'm splitting it off okay oops there we go metacognition and philosophy because we want our machine to be thoughtful um someone i had a conversation many years ago um with someone who i think was actually my girlfriend before we were dating um because i was talking about ai and she's like you know one of the questions that people ask is like aren't you afraid of i was like no i am not afraid of a thoughtful machine what i am afraid of is a thoughtless machine that is controlled by evil people so if you have a thoughtful machine that has goals like you know reduce suffering and um and increase prosperity and it's going to think about the philosophical ramifications of its actions and and its own existence i'm not worried about that machine especially after seeing how well gpt3 can handle those those conversations um it's gpt3 will be far more consistent um ethically and morally than than people or it can be i'm not saying will be it can be with the proper um framing structuring and and fine-tuning um so i'm not afraid of a thoughtful machine as long as it's it's well designed okay so we've got our context prompts our control prompts and our metacognition prompts this one will probably change hey okay so what we do is in our immediate thoughts we say context equals um let's see because we'll have memories and then context yeah all right so context equals to do we'll do newline slash join immediate thoughts um yeah i think that's about right and then so we've got memories so we can have the most recent memories we've got our mental context and then we've got our yep so context prompts and then we'll grab our control prompts so um for c in control prompts and um actually let's delete these because that was old thinking and we'll just copy paste this change that to c and c [Music] and c and i don't think we'll need that all right so generate prompt the memory so we'll need we'll need the context but i think we'll also need the memories in our context so when i do when i build the context so we'll say context equals memories and then we'll do new line and then string and then we'll do new line new line and we'll do our context new line and then a string insert and so then we'll do memories and context okay so this will be a chunk of text that will include our most recent memories and the the member the stacked memories also includes um relevant memories from the past um and so then we've got memories and context there is another loop or another part of this that needs to be added which is declarative knowledge and that's what i'm going to do in a upcoming video about chats with declarative knowledge search and um long-term memory okay so we've got our context so for c and control prompts we generate the prompt based on the context not the memories and then so we get that um c1 yep so that's that print the contact and then we save the memory okay how long is this video we're already at 22 minutes yeah i probably will call it here because um working on artificial cognition like this takes a lot of background thought um so i think i'll probably save the prompt engineering um for the next one um because we've got we've got a whole bunch of prompts to write so we can do probably multiple episodes just on these um and actually probably what i'll do is just delete the prompts that i've got because those were copy pasted from an older project so i'll just start from scratch on those because i don't know i don't know if my thinking has evolved basically um yeah we'll we'll call it here because building an artificial cognition is is is big and also like i just said there's a whole big thing that is missing so i'll just do to do declarative memory so the having a separate system for declarative memory and an artificial cognition might not ultimately be necessary and the reason that i say that is because what one thing that we do is we search for for memories right and so if our artificial cognitive entity has learned something it's going to be in its memory somewhere but that doesn't that doesn't discount the possibility of having like an external source that it can search like the internet or a database or something like that so we need to solve that problem so maybe i'll go ahead and stop it here and then i'll work on the um the chatbot with long-term memory and declarative search okay thanks for watching